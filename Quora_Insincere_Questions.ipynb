{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S23XEx7yPm3M"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# PyDrive reference:\n",
    "# https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tkqqAETPEVx"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/GoogleNews-vectors-negative300\n",
    "!rm -rf glove.840B.300d\n",
    "!rm -rf paragram_300_sl999\n",
    "!rm -rf wiki-news-300d-1M\n",
    "!rm -rf kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HMYQhkpdt_p4",
    "outputId": "3a5fd668-355c-4054-8777-c910dab03ad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
      "/bin/bash: -c: line 0: `rm -rf kaggle (1).json'\n"
     ]
    }
   ],
   "source": [
    "!rm -rf Kaggle\n",
    "!rm -rf kaggle (1).json\n",
    "!rm -rf kaggle.json\n",
    "!rm -rf test.csv.zip\n",
    "!rm -rf train.csv.zip\n",
    "!rm -rf sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g5CT04DqQdbA",
    "outputId": "6cec1dff-00d7-45cb-d381-9364ad738159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "EF6yGycxQtyA",
    "outputId": "bf7b12b3-6be3-42f0-999f-1f30d8a114ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ab952452-f75f-4b73-8ac1-5dff7356f52e\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-ab952452-f75f-4b73-8ac1-5dff7356f52e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    }
   ],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8ZxfMgjiQvwD",
    "outputId": "1901ce60-9b36-44f1-b020-f16e64be8357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "azavvJ-ZQ5re",
    "outputId": "40f2ce6f-38d3-4814-b2e2-587b683e505d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Downloading train.csv.zip to /content\n",
      " 75% 41.0M/54.4M [00:01<00:00, 22.6MB/s]\n",
      "100% 54.4M/54.4M [00:01<00:00, 46.8MB/s]\n",
      "Downloading embeddings.zip to /content\n",
      "100% 5.94G/5.96G [00:51<00:00, 119MB/s]\n",
      "100% 5.96G/5.96G [00:51<00:00, 125MB/s]\n",
      "Downloading sample_submission.csv.zip to /content\n",
      "  0% 0.00/4.08M [00:00<?, ?B/s]\n",
      "100% 4.08M/4.08M [00:00<00:00, 66.9MB/s]\n",
      "Downloading test.csv.zip to /content\n",
      " 77% 12.0M/15.7M [00:00<00:00, 63.2MB/s]\n",
      "100% 15.7M/15.7M [00:00<00:00, 61.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c quora-insincere-questions-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "qUGa6cEtRHEe",
    "outputId": "3f86cad5-2752-4edf-d2cf-958364c507d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Archive:  train.csv.zip\n",
      "  inflating: train.csv               \n",
      "Archive:  test.csv.zip\n",
      "  inflating: test.csv                \n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!unzip train.csv.zip\n",
    "!unzip test.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QeHvV5JCSWEu",
    "outputId": "381f0581-362d-4a07-a4b7-6c3f6a4de0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "!mkdir /content/Kaggle\n",
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "cmSdvt6qSd9w",
    "outputId": "41f9adcc-7137-4d43-e98f-a762712781c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "adc.json\n",
      "embeddings.zip\n",
      "Kaggle\n",
      "kaggle.json\n",
      "Model_LSTM_CONV_1-conv-128-layer-0-dense.h5\n",
      "Model_LSTM_CONV_1-conv-32-layer-0-dense.h5\n",
      "Model_LSTM_CONV_1-conv-64-layer-0-dense.h5\n",
      "Model_LSTM_CONV_2-conv-128-layer-0-dense.h5\n",
      "Model_LSTM_CONV_2-conv-32-layer-0-dense.h5\n",
      "Model_LSTM_CONV_2-conv-64-layer-0-dense.h5\n",
      "sample_data\n",
      "sample_submission.csv.zip\n",
      "test.csv\n",
      "test.csv.zip\n",
      "train.csv\n",
      "train.csv.zip\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-jHYRw1wSzFD",
    "outputId": "a2554793-ec35-48be-9cac-63b83801c8f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!bash -c 'mv train.csv /content/Kaggle'\n",
    "!bash -c 'mv test.csv /content/Kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pTtW6XJXTLGW",
    "outputId": "2eeee5d9-a626-4585-91b4-45e5b33ee39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Kaggle\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgpifgatTs9P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import time\n",
    "import h5py \n",
    "from array import *\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, CuDNNLSTM, GRU, CuDNNGRU, Conv1D, MaxPool1D, Dropout, Embedding, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3idqRTmiTvMR"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0UTrINuGilrm",
    "outputId": "d977cb33-28b5-4c06-b997-c55ac85eb586"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000227734433360e1aae</td>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005e06fbe3045bd2a92</td>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00068a0f7f41f50fc399</td>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  00014894849d00ba98a9  My voice range is A2-C5. My chest voice goes u...\n",
       "1  000156468431f09b3cae           How much does a tutor earn in Bangalore?\n",
       "2  000227734433360e1aae  What are the best made pocket knives under $20...\n",
       "3  0005e06fbe3045bd2a92  Why would they add a hypothetical scenario tha...\n",
       "4  00068a0f7f41f50fc399   What is the dresscode for Techmahindra freshers?"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ODEfZ2NuT0cT",
    "outputId": "e59a7f78-c62e-4da4-90a9-a78a23023a8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "id": "YVtSmVB_T3si",
    "outputId": "f049fa2f-0861-4130-cae0-39f3ee3bd368"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004f9a462a357c33be</td>\n",
       "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005059a06ee19e11ad</td>\n",
       "      <td>Why does Quora automatically ban conservative ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000559f875832745e2e</td>\n",
       "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005bd3426b2d0c8305</td>\n",
       "      <td>Is there such a thing as dressing moderately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00006e6928c5df60eacb</td>\n",
       "      <td>Is it just me or have you ever been in this ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000075f67dd595c3deb5</td>\n",
       "      <td>What can you say about feminism?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000076f3b42776c692de</td>\n",
       "      <td>How were the Calgary Flames founded?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000089792b3fc8026741</td>\n",
       "      <td>What is the dumbest, yet possibly true explana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000092a90bcfbfe8cd88</td>\n",
       "      <td>Can we use our external hard disk as a OS as w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000095680e41a9a6f6e3</td>\n",
       "      <td>I am 30, living at home and have no boyfriend....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0000a89942e3143e333a</td>\n",
       "      <td>What do you know about Bram Fischer and the Ri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0000b8e1279eaa0a7062</td>\n",
       "      <td>How difficult is it to find a good instructor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0000bc0f62500f55959f</td>\n",
       "      <td>Have you licked the skin of a corpse?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0000ce6c31f14d3e09ec</td>\n",
       "      <td>Do you think Amazon will adopt an in house app...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0000d329332845b8a7fa</td>\n",
       "      <td>How many baronies might exist within a county ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0000dd973dfd35508c16</td>\n",
       "      <td>How I know whether a girl had done sex before ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0000e4d455f9c8877dc9</td>\n",
       "      <td>How do I become a fast learner both in my prof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0000e91571b60c2fb487</td>\n",
       "      <td>Has the United States become the largest dicta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000101ac65db6e4a1c13</td>\n",
       "      <td>What is the strangest phenomenon you know of, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00010632971fe5e3e0e2</td>\n",
       "      <td>Should I leave my friends and find new ones?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00010a2e064c3e8f152a</td>\n",
       "      <td>Can you make Amazon Alexa trigger events in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00012011b6c7759461e8</td>\n",
       "      <td>Why haven't two democracies never ever went fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00012fd5128d576260ab</td>\n",
       "      <td>How can I top CBSE in 6 months?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0001303b1799a042b26b</td>\n",
       "      <td>What should I know before visiting Mcleodganj ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00013a8152b5f37b780e</td>\n",
       "      <td>How do modern military submarines reduce noise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306092</th>\n",
       "      <td>fffeaee9356b09078753</td>\n",
       "      <td>I hardly talk about my interests (reading and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306093</th>\n",
       "      <td>fffeba722d9b371bd1b9</td>\n",
       "      <td>How is it to have intimate relation with your ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306094</th>\n",
       "      <td>fffee269360dd0d3947a</td>\n",
       "      <td>Why is it when singers have lyrics about voice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306095</th>\n",
       "      <td>fffee78cd374c14d15f8</td>\n",
       "      <td>Does the ginger plant naturally contain sugar?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306096</th>\n",
       "      <td>fffef2de11d291406fdb</td>\n",
       "      <td>Are technological advances in medicine doing m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306097</th>\n",
       "      <td>fffef6ecdfd410ddd5c0</td>\n",
       "      <td>Can I pass class 11 math if I have 85 marks ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306098</th>\n",
       "      <td>ffff0e0bad740a698663</td>\n",
       "      <td>Do you think that the physical traits you are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306099</th>\n",
       "      <td>ffff0e4ea1bb6e16feec</td>\n",
       "      <td>Do pakis smell of curry and shit?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306100</th>\n",
       "      <td>ffff265faac66b6085da</td>\n",
       "      <td>On Quora is it as good as downvoting the answe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306101</th>\n",
       "      <td>ffff2adc1895bc0c32e1</td>\n",
       "      <td>Are the Wahabis Muslim's puritans?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306102</th>\n",
       "      <td>ffff3778790af9baae76</td>\n",
       "      <td>What steps can I take to live a normal life if...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306103</th>\n",
       "      <td>ffff3f0a2449ffe4b9ff</td>\n",
       "      <td>Isn't Trump right after all? Why should the US...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306104</th>\n",
       "      <td>ffff41393389d4206066</td>\n",
       "      <td>Is 33 too late for a career in creative advert...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306105</th>\n",
       "      <td>ffff42493fc203cd9532</td>\n",
       "      <td>What is difference between the filteration wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306106</th>\n",
       "      <td>ffff48dd47bee89fff79</td>\n",
       "      <td>If the universe \"popped\" into existence from n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306107</th>\n",
       "      <td>ffff5fd051a032f32a39</td>\n",
       "      <td>How does a shared service technology team meas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306108</th>\n",
       "      <td>ffff6d528040d3888b93</td>\n",
       "      <td>How is DSATM civil engineering?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306109</th>\n",
       "      <td>ffff8776cd30cdc8d7f8</td>\n",
       "      <td>Do you know any problem that depends solely on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306110</th>\n",
       "      <td>ffff94d427ade3716cd1</td>\n",
       "      <td>What are some comic ideas for you Tube videos ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306111</th>\n",
       "      <td>ffffa382c58368071dc9</td>\n",
       "      <td>If you had $10 million of Bitcoin, could you s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306112</th>\n",
       "      <td>ffffa5b0fa76431c063f</td>\n",
       "      <td>Are you ashamed of being an Indian?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306113</th>\n",
       "      <td>ffffae5dbda3dc9e9771</td>\n",
       "      <td>What are the methods to determine fossil ages ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306114</th>\n",
       "      <td>ffffba7c4888798571c1</td>\n",
       "      <td>What is your story today?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306115</th>\n",
       "      <td>ffffc0c7158658a06fd9</td>\n",
       "      <td>How do I consume 150 gms protein daily both ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306116</th>\n",
       "      <td>ffffc404da586ac5a08f</td>\n",
       "      <td>What are the good career options for a msc che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "5        00004f9a462a357c33be   \n",
       "6        00005059a06ee19e11ad   \n",
       "7        0000559f875832745e2e   \n",
       "8        00005bd3426b2d0c8305   \n",
       "9        00006e6928c5df60eacb   \n",
       "10       000075f67dd595c3deb5   \n",
       "11       000076f3b42776c692de   \n",
       "12       000089792b3fc8026741   \n",
       "13       000092a90bcfbfe8cd88   \n",
       "14       000095680e41a9a6f6e3   \n",
       "15       0000a89942e3143e333a   \n",
       "16       0000b8e1279eaa0a7062   \n",
       "17       0000bc0f62500f55959f   \n",
       "18       0000ce6c31f14d3e09ec   \n",
       "19       0000d329332845b8a7fa   \n",
       "20       0000dd973dfd35508c16   \n",
       "21       0000e4d455f9c8877dc9   \n",
       "22       0000e91571b60c2fb487   \n",
       "23       000101ac65db6e4a1c13   \n",
       "24       00010632971fe5e3e0e2   \n",
       "25       00010a2e064c3e8f152a   \n",
       "26       00012011b6c7759461e8   \n",
       "27       00012fd5128d576260ab   \n",
       "28       0001303b1799a042b26b   \n",
       "29       00013a8152b5f37b780e   \n",
       "...                       ...   \n",
       "1306092  fffeaee9356b09078753   \n",
       "1306093  fffeba722d9b371bd1b9   \n",
       "1306094  fffee269360dd0d3947a   \n",
       "1306095  fffee78cd374c14d15f8   \n",
       "1306096  fffef2de11d291406fdb   \n",
       "1306097  fffef6ecdfd410ddd5c0   \n",
       "1306098  ffff0e0bad740a698663   \n",
       "1306099  ffff0e4ea1bb6e16feec   \n",
       "1306100  ffff265faac66b6085da   \n",
       "1306101  ffff2adc1895bc0c32e1   \n",
       "1306102  ffff3778790af9baae76   \n",
       "1306103  ffff3f0a2449ffe4b9ff   \n",
       "1306104  ffff41393389d4206066   \n",
       "1306105  ffff42493fc203cd9532   \n",
       "1306106  ffff48dd47bee89fff79   \n",
       "1306107  ffff5fd051a032f32a39   \n",
       "1306108  ffff6d528040d3888b93   \n",
       "1306109  ffff8776cd30cdc8d7f8   \n",
       "1306110  ffff94d427ade3716cd1   \n",
       "1306111  ffffa382c58368071dc9   \n",
       "1306112  ffffa5b0fa76431c063f   \n",
       "1306113  ffffae5dbda3dc9e9771   \n",
       "1306114  ffffba7c4888798571c1   \n",
       "1306115  ffffc0c7158658a06fd9   \n",
       "1306116  ffffc404da586ac5a08f   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                             question_text  target  \n",
       "0        How did Quebec nationalists see their province...       0  \n",
       "1        Do you have an adopted dog, how would you enco...       0  \n",
       "2        Why does velocity affect time? Does velocity a...       0  \n",
       "3        How did Otto von Guericke used the Magdeburg h...       0  \n",
       "4        Can I convert montra helicon D to a mountain b...       0  \n",
       "5        Is Gaza slowly becoming Auschwitz, Dachau or T...       0  \n",
       "6        Why does Quora automatically ban conservative ...       0  \n",
       "7        Is it crazy if I wash or wipe my groceries off...       0  \n",
       "8        Is there such a thing as dressing moderately, ...       0  \n",
       "9        Is it just me or have you ever been in this ph...       0  \n",
       "10                        What can you say about feminism?       0  \n",
       "11                    How were the Calgary Flames founded?       0  \n",
       "12       What is the dumbest, yet possibly true explana...       0  \n",
       "13       Can we use our external hard disk as a OS as w...       0  \n",
       "14       I am 30, living at home and have no boyfriend....       0  \n",
       "15       What do you know about Bram Fischer and the Ri...       0  \n",
       "16       How difficult is it to find a good instructor ...       0  \n",
       "17                   Have you licked the skin of a corpse?       0  \n",
       "18       Do you think Amazon will adopt an in house app...       0  \n",
       "19       How many baronies might exist within a county ...       0  \n",
       "20       How I know whether a girl had done sex before ...       0  \n",
       "21       How do I become a fast learner both in my prof...       0  \n",
       "22       Has the United States become the largest dicta...       1  \n",
       "23       What is the strangest phenomenon you know of, ...       0  \n",
       "24            Should I leave my friends and find new ones?       0  \n",
       "25       Can you make Amazon Alexa trigger events in th...       0  \n",
       "26       Why haven't two democracies never ever went fo...       0  \n",
       "27                         How can I top CBSE in 6 months?       0  \n",
       "28       What should I know before visiting Mcleodganj ...       0  \n",
       "29       How do modern military submarines reduce noise...       0  \n",
       "...                                                    ...     ...  \n",
       "1306092  I hardly talk about my interests (reading and ...       0  \n",
       "1306093  How is it to have intimate relation with your ...       1  \n",
       "1306094  Why is it when singers have lyrics about voice...       1  \n",
       "1306095     Does the ginger plant naturally contain sugar?       0  \n",
       "1306096  Are technological advances in medicine doing m...       0  \n",
       "1306097  Can I pass class 11 math if I have 85 marks ou...       0  \n",
       "1306098  Do you think that the physical traits you are ...       0  \n",
       "1306099                  Do pakis smell of curry and shit?       1  \n",
       "1306100  On Quora is it as good as downvoting the answe...       0  \n",
       "1306101                 Are the Wahabis Muslim's puritans?       0  \n",
       "1306102  What steps can I take to live a normal life if...       0  \n",
       "1306103  Isn't Trump right after all? Why should the US...       1  \n",
       "1306104  Is 33 too late for a career in creative advert...       0  \n",
       "1306105  What is difference between the filteration wor...       0  \n",
       "1306106  If the universe \"popped\" into existence from n...       0  \n",
       "1306107  How does a shared service technology team meas...       0  \n",
       "1306108                    How is DSATM civil engineering?       0  \n",
       "1306109  Do you know any problem that depends solely on...       0  \n",
       "1306110  What are some comic ideas for you Tube videos ...       0  \n",
       "1306111  If you had $10 million of Bitcoin, could you s...       0  \n",
       "1306112                Are you ashamed of being an Indian?       1  \n",
       "1306113  What are the methods to determine fossil ages ...       0  \n",
       "1306114                          What is your story today?       0  \n",
       "1306115  How do I consume 150 gms protein daily both ve...       0  \n",
       "1306116  What are the good career options for a msc che...       0  \n",
       "1306117  What other technical skills do you need as a c...       0  \n",
       "1306118  Does MS in ECE have good job prospects in USA ...       0  \n",
       "1306119                          Is foam insulation toxic?       0  \n",
       "1306120  How can one start a research project based on ...       0  \n",
       "1306121  Who wins in a battle between a Wolverine and a...       0  \n",
       "\n",
       "[1306122 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LV0IVEIIWG_I"
   },
   "source": [
    "The training data includes the question that was asked, and whether it was identified as insincere (target = 1). The ground-truth labels contain some amount of noise: they are not guaranteed to be perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QI6ox5tBT8FF",
    "outputId": "a9353420-a4f1-45be-de62-351cee6d1ee2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are you ashamed of being an Indian?'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[1306112][\"question_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s-d5QGhFUYwG",
    "outputId": "19b6bdc8-c752-4e06-ef61-2790400359cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"target\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIq7ITgrWMvg"
   },
   "outputs": [],
   "source": [
    "# To find all the punctuations.\n",
    "punctuation = []\n",
    "length = int(len(train_data))\n",
    "for i in range(length):\n",
    "  punctuation.append( re.findall(r\"[^a-zA-Z0-9 ]\", train_data[\"question_text\"][i]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QGw6cIrkcqjQ",
    "outputId": "b6638ffc-c47a-4399-d0b0-d1d4f84bff51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.', '*', '/', ')', '…', '(', '=', '?', '\"', \"'\", '$', '-', ','}\n"
     ]
    }
   ],
   "source": [
    "# To print all unique punctuations from top 100 questions.\n",
    "myset = set()\n",
    "for i in range(100):\n",
    "  for j in range(len(punctuation[i])):\n",
    "    myset.add(punctuation[i][j])\n",
    "print(myset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "DYpkUrOgkDpg",
    "outputId": "e6e40a11-14cf-4fc6-9440-d9d61c3423a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['?'],\n",
       " [',', '?'],\n",
       " ['?', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " [',', '?'],\n",
       " [',', '?'],\n",
       " ['?', '.'],\n",
       " [',', ',', '?'],\n",
       " [',', '/', '.', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " [',', '?'],\n",
       " ['.', '?'],\n",
       " [',', '.', '.', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " [',', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " [\"'\", '?', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?', '?'],\n",
       " ['?'],\n",
       " [',', '/', '?'],\n",
       " ['?', '?', '-', '-', '?'],\n",
       " ['?'],\n",
       " ['/', '(', ')', '?'],\n",
       " [',', \"'\", '?'],\n",
       " ['?'],\n",
       " [',', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['.', '?'],\n",
       " ['?'],\n",
       " [\"'\", ',', '?'],\n",
       " ['\"', '\"', '?'],\n",
       " ['.', '?'],\n",
       " [',', '-', '?'],\n",
       " [',', '?'],\n",
       " [',', '?'],\n",
       " ['.', '?'],\n",
       " ['?'],\n",
       " ['(', ',', ',', ')', '(', '.', ')', ',', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " [\"'\", '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " [',', ',', '?'],\n",
       " ['?'],\n",
       " [\"'\", '?'],\n",
       " ['?'],\n",
       " [\"'\", '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?', '?'],\n",
       " ['?', '.'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['$', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['(', '.', ')', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['?', '?'],\n",
       " [',', \"'\", '.', '.', '?'],\n",
       " ['?'],\n",
       " ['.', '-', '=', '.', '?'],\n",
       " ['?'],\n",
       " ['?'],\n",
       " ['…', '(', '*', ')', '-', '*', '=', '?'],\n",
       " ['?'],\n",
       " [',', '?']]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Dymzz0eiJi3"
   },
   "source": [
    "We have come up with different hindi letters, lets see if they are acrually present in the questions or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6wK4F4rEiYxZ",
    "outputId": "87dd7d7e-8396-4683-97a4-596b9e7ad45c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"question_text\"][0].find(\"1960\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "kd93QWvWf02U",
    "outputId": "29370b63-85ff-4f19-9116-ca391f99a917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?']\n",
      "[',', '?']\n"
     ]
    }
   ],
   "source": [
    "print(punctuation[0])\n",
    "print(punctuation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "MIr8va3t4uRd",
    "outputId": "0211ed43-42d7-437f-ab2d-80ae7f0b43cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.18.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZiquV6C4753"
   },
   "outputs": [],
   "source": [
    "website_url = requests.get(\"https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions\").text\n",
    "soup = BeautifulSoup(website_url, 'lxml')\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1Hyl0Fq557P"
   },
   "outputs": [],
   "source": [
    "# we need \"wikitable sortable\" file from the html script.\n",
    "table = soup.find('table', {'class' : 'wikitable sortable'})\n",
    "#table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "sov5tqmU6qhj",
    "outputId": "49a41a85-9336-44b7-9da8-065e5ef9038c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ain't\", \"amn't\", \"aren't\", \"can't (rarely, cain't)\", \"'cause\", \"could've\", \"couldn't\", \"couldn't've\", \"daren't\", \"daresn't\", \"dasn't\", \"didn't\", \"doesn't\", \"don't\", \"e'er\", \"everyone's\", 'finna', 'gimme', 'giv’n', 'gonna', \"gon't\", 'gotta', \"hadn't\", \"hasn't\", \"haven't\", \"he'd\", \"he'll\", \"he's\", \"he've\", \"how'd\", 'howdy', \"how'll\", \"how're\", \"how's\", \"I'd\", \"I'll\", \"I'm\", \"I'm'a\", \"I'm'o\", \"I've\", \"isn't\", \"it'd\", \"it'll\", \"it's\", \"let's\", \"ma'am\", \"mayn't\", \"may've\", \"mightn't\", \"might've\", \"mustn't\", \"mustn't've\", \"must've\", \"needn't\", \"ne'er\", \"o'clock\", \"o'er\", \"ol'\", \"oughtn't\", \"'s\", \"shalln't\", \"shan't\", \"she'd\", \"she'll\", \"she's\", \"should've\", \"shouldn't\", \"shouldn't've\", \"somebody's\", \"someone's\", \"something's\", \"so're\", \"that'll\", \"that're\", \"that's\", \"that'd\", \"there'd\", \"there'll\", \"there're\", \"there's\", \"these're\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this's\", \"those're\", \"'tis\", \"'twas\", \"wasn't\", \"we'd\", \"we'd've\", \"we'll\", \"we're\", \"we've\", \"weren't\", \"what'd\", \"what'll\", \"what're\", \"what's\", \"what've\", \"when's\", \"where'd\", \"where're\", \"where's\", \"where've\", \"which's\", \"who'd\", \"who'd've\", \"who'll\", \"whom'st\", \"whom'st'd've\", \"who're\", \"who's\", \"who've\", \"why'd\", \"why're\", \"why's\", \"won't\", \"would've\", \"wouldn't\", \"y'all\", \"y'all'd've\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"noun's\", \"noun(s)'re\"]\n",
      "['am not / is not / are not / has not / have not / did not (colloquial)[1]\\n', 'am not[2]\\n', 'are not[3]\\n', 'cannot\\n', 'because\\n', 'could have\\n', 'could not\\n', 'could not have\\n', 'dare not / dared not\\n', 'dare not\\n', 'dare not\\n', 'did not\\n', 'does not\\n', 'do not / does not[4]\\n', 'ever\\n', 'everyone is\\n', 'fixing to / going to (colloquial)\\n', 'give me\\n', 'given\\n', 'going to\\n', 'go not (colloquial)\\n', 'got to\\n', 'had not\\n', 'has not\\n', 'have not\\n', 'he had / he would\\n', 'he shall / he will\\n', 'he has / he is\\n', 'he have\\n', 'how did / how would\\n', 'how do you do / how do you fare\\n', 'how will\\n', 'how are\\n', 'how has / how is / how does\\n', 'I had / I would\\n', 'I shall / I will\\n', 'I am\\n', 'I am about to\\n', 'I am going to\\n', 'I have\\n', 'is not\\n', 'it would\\n', 'it shall / it will\\n', 'it has / it is\\n', 'let us\\n', 'madam\\n', 'may not\\n', 'may have\\n', 'might not\\n', 'might have\\n', 'must not\\n', 'must not have\\n', 'must have\\n', 'need not\\n', 'never\\n', 'of the clock\\n', 'over\\n', 'old\\n', 'ought not\\n', 'is, has, does, or us\\n', 'shall not (archaic)\\n', 'shall not\\n', 'she had / she would\\n', 'she shall / she will\\n', 'she has / she is\\n', 'should have\\n', 'should not\\n', 'should not have\\n', 'somebody has / somebody is\\n', 'someone has / someone is\\n', 'something has / something is\\n', 'so are (colloquial)\\n', 'that shall / that will\\n', 'that are\\n', 'that has / that is\\n', 'that would / that had\\n', 'there had / there would\\n', 'there shall / there will\\n', 'there are\\n', 'there has / there is\\n', 'these are\\n', 'they had / they would\\n', 'they shall / they will\\n', 'they are / they were\\n', 'they have\\n', 'this has / this is\\n', 'those are\\n', 'it is\\n', 'it was\\n', 'was not\\n', 'we had / we would\\n', 'we would have\\n', 'we will\\n', 'we are\\n', 'we have\\n', 'were not\\n', 'what did\\n', 'what shall / what will/ what all\\n', 'what are/what were\\n', 'what has / what is / what does\\n', 'what have\\n', 'when has / when is\\n', 'where did\\n', 'where are\\n', 'where has / where is / where does\\n', 'where have\\n', 'which has / which is\\n', 'who would / who had / who did\\n', 'who would have\\n', 'who shall / who will\\n', 'whom hast\\n', 'whom hast had have\\n', 'who are\\n', 'who has / who is / who does\\n', 'who have\\n', 'why did\\n', 'why are\\n', 'why has / why is / why does\\n', 'will not\\n', 'would have\\n', 'would not\\n', 'you all (colloquial)\\n', 'you all would have (colloquial)\\n', 'you had / you would\\n', 'you shall / you will\\n', 'you are\\n', 'you have\\n', 'noun is (possessive forms of many nouns are homographic to this contraction)\\n', 'noun(s) are (forms of many nouns are homographic to this contraction)\\n']\n"
     ]
    }
   ],
   "source": [
    "#columns = soup.find_all('td')\n",
    "contraction_list = []\n",
    "meaning_list = []\n",
    "for row in table.find_all('tr')[1:]:  # iterate over the rows, starting from \n",
    "                                      # the second (first one is the header row)\n",
    "    contraction = row.find_all('td')[0]  #  the Symbol col is the first <td> in every row \n",
    "    meaning = row.find_all('td')[1]  #  the Symbol col is the first <td> in every row\n",
    "        \n",
    "    contraction_list.append(contraction.text)\n",
    "    meaning_list.append(meaning.text)\n",
    "\n",
    "print(contraction_list)\n",
    "print(meaning_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "QiBFlBhf83ap",
    "outputId": "44f87a07-db6a-405a-a603-a46af41a7957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ain't\", \"amn't\", \"aren't\", \"can't\", 'rarely', \"cain't\", \"'cause\", \"could've\", \"couldn't\", \"couldn't've\", \"daren't\", \"daresn't\", \"dasn't\", \"didn't\", \"doesn't\", \"don't\", \"e'er\", \"everyone's\", 'finna', 'gimme', 'giv’n', 'gonna', \"gon't\", 'gotta', \"hadn't\", \"hasn't\", \"haven't\", \"he'd\", \"he'll\", \"he's\", \"he've\", \"how'd\", 'howdy', \"how'll\", \"how're\", \"how's\", \"I'd\", \"I'll\", \"I'm\", \"I'm'a\", \"I'm'o\", \"I've\", \"isn't\", \"it'd\", \"it'll\", \"it's\", \"let's\", \"ma'am\", \"mayn't\", \"may've\", \"mightn't\", \"might've\", \"mustn't\", \"mustn't've\", \"must've\", \"needn't\", \"ne'er\", \"o'clock\", \"o'er\", \"ol'\", \"oughtn't\", \"'s\", \"shalln't\", \"shan't\", \"she'd\", \"she'll\", \"she's\", \"should've\", \"shouldn't\", \"shouldn't've\", \"somebody's\", \"someone's\", \"something's\", \"so're\", \"that'll\", \"that're\", \"that's\", \"that'd\", \"there'd\", \"there'll\", \"there're\", \"there's\", \"these're\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this's\", \"those're\", \"'tis\", \"'twas\", \"wasn't\", \"we'd\", \"we'd've\", \"we'll\", \"we're\", \"we've\", \"weren't\", \"what'd\", \"what'll\", \"what're\", \"what's\", \"what've\", \"when's\", \"where'd\", \"where're\", \"where's\", \"where've\", \"which's\", \"who'd\", \"who'd've\", \"who'll\", \"whom'st\", \"whom'st'd've\", \"who're\", \"who's\", \"who've\", \"why'd\", \"why're\", \"why's\", \"won't\", \"would've\", \"wouldn't\", \"y'all\", \"y'all'd've\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"noun's\", \"noun(s)'re\"]\n",
      "['am not / is not / are not / has not / have not / did not (colloquial)[1]\\n', 'am not[2]\\n', 'are not[3]\\n', 'cannot\\n', 'cannot\\n', 'cannot\\n', 'because\\n', 'could have\\n', 'could not\\n', 'could not have\\n', 'dare not / dared not\\n', 'dare not\\n', 'dare not\\n', 'did not\\n', 'does not\\n', 'do not / does not[4]\\n', 'ever\\n', 'everyone is\\n', 'fixing to / going to (colloquial)\\n', 'give me\\n', 'given\\n', 'going to\\n', 'go not (colloquial)\\n', 'got to\\n', 'had not\\n', 'has not\\n', 'have not\\n', 'he had / he would\\n', 'he shall / he will\\n', 'he has / he is\\n', 'he have\\n', 'how did / how would\\n', 'how do you do / how do you fare\\n', 'how will\\n', 'how are\\n', 'how has / how is / how does\\n', 'I had / I would\\n', 'I shall / I will\\n', 'I am\\n', 'I am about to\\n', 'I am going to\\n', 'I have\\n', 'is not\\n', 'it would\\n', 'it shall / it will\\n', 'it has / it is\\n', 'let us\\n', 'madam\\n', 'may not\\n', 'may have\\n', 'might not\\n', 'might have\\n', 'must not\\n', 'must not have\\n', 'must have\\n', 'need not\\n', 'never\\n', 'of the clock\\n', 'over\\n', 'old\\n', 'ought not\\n', 'is, has, does, or us\\n', 'shall not (archaic)\\n', 'shall not\\n', 'she had / she would\\n', 'she shall / she will\\n', 'she has / she is\\n', 'should have\\n', 'should not\\n', 'should not have\\n', 'somebody has / somebody is\\n', 'someone has / someone is\\n', 'something has / something is\\n', 'so are (colloquial)\\n', 'that shall / that will\\n', 'that are\\n', 'that has / that is\\n', 'that would / that had\\n', 'there had / there would\\n', 'there shall / there will\\n', 'there are\\n', 'there has / there is\\n', 'these are\\n', 'they had / they would\\n', 'they shall / they will\\n', 'they are / they were\\n', 'they have\\n', 'this has / this is\\n', 'those are\\n', 'it is\\n', 'it was\\n', 'was not\\n', 'we had / we would\\n', 'we would have\\n', 'we will\\n', 'we are\\n', 'we have\\n', 'were not\\n', 'what did\\n', 'what shall / what will/ what all\\n', 'what are/what were\\n', 'what has / what is / what does\\n', 'what have\\n', 'when has / when is\\n', 'where did\\n', 'where are\\n', 'where has / where is / where does\\n', 'where have\\n', 'which has / which is\\n', 'who would / who had / who did\\n', 'who would have\\n', 'who shall / who will\\n', 'whom hast\\n', 'whom hast had have\\n', 'who are\\n', 'who has / who is / who does\\n', 'who have\\n', 'why did\\n', 'why are\\n', 'why has / why is / why does\\n', 'will not\\n', 'would have\\n', 'would not\\n', 'you all (colloquial)\\n', 'you all would have (colloquial)\\n', 'you had / you would\\n', 'you shall / you will\\n', 'you are\\n', 'you have\\n', 'noun is (possessive forms of many nouns are homographic to this contraction)\\n', 'noun(s) are (forms of many nouns are homographic to this contraction)\\n']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the words\n",
    "\n",
    "#splitword = []\n",
    "#print(len(contraction_list))\n",
    "#print(len(meaning_list))\n",
    "for word in contraction_list:\n",
    "  #print(word)\n",
    "  if (' ' in word):\n",
    "    position_to_add = contraction_list.index(word)\n",
    "    meaning_word = meaning_list[position_to_add]\n",
    "    \n",
    "    word_to_process = re.sub(r'[(),]', \"\", word)\n",
    "    splitword = word_to_process.split()\n",
    "    length_split_word = len(splitword)\n",
    "    #print(splitword)\n",
    "    \n",
    "    contraction_list.remove(word)\n",
    "    meaning_list.pop(position_to_add)\n",
    "    \n",
    "    for i in range(len(splitword)):\n",
    "      contraction_list.insert((position_to_add + i), splitword[i] )\n",
    "      meaning_list.insert((position_to_add + i), meaning_word)\n",
    "    break\n",
    "    #print(splitword)\n",
    "print(contraction_list)\n",
    "print(meaning_list)\n",
    "\n",
    "#print(len(contraction_list))\n",
    "#print(len(meaning_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Or4OcGNEMhY8",
    "outputId": "24e8bd5e-0e55-4e7d-8442-fca1ae667243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ain't\", \"amn't\", \"aren't\", \"can't\", 'rarely', \"cain't\", \"'cause\", \"could've\", \"couldn't\", \"couldn't've\", \"daren't\", \"daresn't\", \"dasn't\", \"didn't\", \"doesn't\", \"don't\", \"e'er\", \"everyone's\", 'finna', 'gimme', 'gonna', \"gon't\", 'gotta', \"hadn't\", \"hasn't\", \"haven't\", \"he'd\", \"he'll\", \"he's\", \"he've\", \"how'd\", \"how'll\", \"how're\", \"how's\", \"I'd\", \"I'll\", \"I'm\", \"I'm'a\", \"I'm'o\", \"I've\", \"isn't\", \"it'd\", \"it'll\", \"it's\", \"let's\", \"mayn't\", \"may've\", \"mightn't\", \"might've\", \"mustn't\", \"mustn't've\", \"must've\", \"needn't\", \"ne'er\", \"o'clock\", \"o'er\", \"ol'\", \"oughtn't\", \"'s\", \"shalln't\", \"shan't\", \"she'd\", \"she'll\", \"she's\", \"should've\", \"shouldn't\", \"shouldn't've\", \"somebody's\", \"someone's\", \"something's\", \"so're\", \"that'll\", \"that're\", \"that's\", \"that'd\", \"there'd\", \"there'll\", \"there're\", \"there's\", \"these're\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this's\", \"those're\", \"'tis\", \"'twas\", \"wasn't\", \"we'd\", \"we'd've\", \"we'll\", \"we're\", \"we've\", \"weren't\", \"what'd\", \"what'll\", \"what're\", \"what's\", \"what've\", \"when's\", \"where'd\", \"where're\", \"where's\", \"where've\", \"which's\", \"who'd\", \"who'd've\", \"who'll\", \"who're\", \"who's\", \"who've\", \"why'd\", \"why're\", \"why's\", \"won't\", \"would've\", \"wouldn't\", \"y'all\", \"you'd\", \"you'll\", \"you're\", \"you've\"]\n",
      "['am not / is not / are not / has not / have not / did not (colloquial)[1]\\n', 'am not[2]\\n', 'are not[3]\\n', 'cannot\\n', 'cannot\\n', 'cannot\\n', 'because\\n', 'could have\\n', 'could not\\n', 'could not have\\n', 'dare not / dared not\\n', 'dare not\\n', 'dare not\\n', 'did not\\n', 'does not\\n', 'do not / does not[4]\\n', 'ever\\n', 'everyone is\\n', 'fixing to (colloquial)\\n', 'give me\\n', 'going to\\n', 'go not (colloquial)\\n', 'got to\\n', 'had not\\n', 'has not\\n', 'have not\\n', 'he had / he would\\n', 'he shall / he will\\n', 'he has / he is\\n', 'he have\\n', 'how did / how would\\n', 'how will\\n', 'how are\\n', 'how has / how is / how does\\n', 'I had / I would\\n', 'I shall / I will\\n', 'I am\\n', 'I am about to\\n', 'I am going to\\n', 'I have\\n', 'is not\\n', 'it would\\n', 'it shall / it will\\n', 'it has / it is\\n', 'let us\\n', 'may not\\n', 'may have\\n', 'might not\\n', 'might have\\n', 'must not\\n', 'must not have\\n', 'must have\\n', 'need not\\n', 'never\\n', 'of the clock\\n', 'over\\n', 'old\\n', 'ought not\\n', 'is, has, does, or us\\n', 'shall not (archaic)\\n', 'shall not\\n', 'she had / she would\\n', 'she shall / she will\\n', 'she has / she is\\n', 'should have\\n', 'should not\\n', 'should not have\\n', 'somebody has / somebody is\\n', 'someone has / someone is\\n', 'something has / something is\\n', 'so are (colloquial)\\n', 'that shall / that will\\n', 'that are\\n', 'that has / that is\\n', 'that would / that had\\n', 'there had / there would\\n', 'there shall / there will\\n', 'there are\\n', 'there has / there is\\n', 'these are\\n', 'they had / they would\\n', 'they shall / they will\\n', 'they are / they were\\n', 'they have\\n', 'this has / this is\\n', 'those are\\n', 'it is\\n', 'it was\\n', 'was not\\n', 'we had / we would\\n', 'we would have\\n', 'we will\\n', 'we are\\n', 'we have\\n', 'were not\\n', 'what did\\n', 'what shall / what will/ what all\\n', 'what are\\n', 'what has / what is / what does\\n', 'what have\\n', 'when has / when is\\n', 'where did\\n', 'where are\\n', 'where has / where is / where does\\n', 'where have\\n', 'which has / which is\\n', 'who would / who had / who did\\n', 'who would have\\n', 'who shall / who will\\n', 'who are\\n', 'who has / who is / who does\\n', 'who have\\n', 'why did\\n', 'why are\\n', 'why has / why is / why does\\n', 'will not\\n', 'would have\\n', 'would not\\n', 'you all (colloquial)\\n', 'you had / you would\\n', 'you shall / you will\\n', 'you are\\n', 'you have\\n']\n"
     ]
    }
   ],
   "source": [
    "# pop out last two element\n",
    "del contraction_list[-2:]\n",
    "del meaning_list[-2:]\n",
    "\n",
    "print(contraction_list)\n",
    "print(meaning_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJ7sAuguL3uD"
   },
   "source": [
    "Now, our contraction list is well defined, we need to process meaning list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfTFP9IWKonb"
   },
   "outputs": [],
   "source": [
    "meaningfull_list = []\n",
    "def process_word(word):\n",
    "  \n",
    "  word = re.sub(r\"[0-9]\", \"\", word)\n",
    "  word = re.sub(r\"\\n\", \"\", word)\n",
    "  word = word.replace('[','').replace(']','')\n",
    "  word = word.replace(' (colloquial)', '')\n",
    "  word = word.replace(' (archaic)', '')\n",
    "  meaningfull_list.append(word)\n",
    "  \n",
    "  return meaningfull_list\n",
    "#[re.sub(r'[0-9]', '', word) if ('[]' in word) else x for x in meaning_list]\n",
    "\n",
    "for word in meaning_list:\n",
    "  meaningfull_list = process_word(word)\n",
    "#meaningfull_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chw-BGSIWDl3"
   },
   "source": [
    "Now that we have process the words, lets split these too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ZaT-1bVuWCxn",
    "outputId": "ed31a275-d8f1-482b-e0f5-19344b45ee0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "123\n",
      "[\"ain't\", \"amn't\", \"aren't\", \"can't\", 'rarely', \"cain't\", \"'cause\", \"could've\", \"couldn't\", \"couldn't've\", \"daren't\", \"daresn't\", \"dasn't\", \"didn't\", \"doesn't\", \"don't\", \"e'er\", \"everyone's\", 'finna', 'gimme', 'gonna', \"gon't\", 'gotta', \"hadn't\", \"hasn't\", \"haven't\", \"he'd\", \"he'll\", \"he's\", \"he've\", \"how'd\", \"how'll\", \"how're\", \"how's\", \"I'd\", \"I'll\", \"I'm\", \"I'm'a\", \"I'm'o\", \"I've\", \"isn't\", \"it'd\", \"it'll\", \"it's\", \"let's\", \"mayn't\", \"may've\", \"mightn't\", \"might've\", \"mustn't\", \"mustn't've\", \"must've\", \"needn't\", \"ne'er\", \"o'clock\", \"o'er\", \"ol'\", \"oughtn't\", \"'s\", \"shalln't\", \"shan't\", \"she'd\", \"she'll\", \"she's\", \"should've\", \"shouldn't\", \"shouldn't've\", \"somebody's\", \"someone's\", \"something's\", \"so're\", \"that'll\", \"that're\", \"that's\", \"that'd\", \"there'd\", \"there'll\", \"there're\", \"there's\", \"these're\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this's\", \"those're\", \"'tis\", \"'twas\", \"wasn't\", \"we'd\", \"we'd've\", \"we'll\", \"we're\", \"we've\", \"weren't\", \"what'd\", \"what'll\", \"what're\", \"what's\", \"what've\", \"when's\", \"where'd\", \"where're\", \"where's\", \"where've\", \"which's\", \"who'd\", \"who'd've\", \"who'll\", \"who're\", \"who's\", \"who've\", \"why'd\", \"why're\", \"why's\", \"won't\", \"would've\", \"wouldn't\", \"y'all\", \"you'd\", \"you'll\", \"you're\", \"you've\"]\n",
      "['am not', 'am not', 'are not', 'cannot', 'cannot', 'cannot', 'because', 'could have', 'could not', 'could not have', 'dare not', 'dare not', 'dare not', 'did not', 'does not', 'do not', 'ever', 'everyone is', 'fixing to', 'give me', 'going to', 'go not', 'got to', 'had not', 'has not', 'have not', 'he had', 'he shall', 'he has', 'he have', 'how did', 'how will', 'how are', 'how has', 'I had', 'I shall', 'I am', 'I am about to', 'I am going to', 'I have', 'is not', 'it would', 'it shall', 'it has', 'let us', 'may not', 'may have', 'might not', 'might have', 'must not', 'must not have', 'must have', 'need not', 'never', 'of the clock', 'over', 'old', 'ought not', 'is', 'shall not', 'shall not', 'she had', 'she shall', 'she has', 'should have', 'should not', 'should not have', 'somebody has', 'someone has', 'something has', 'so are', 'that shall', 'that are', 'that has', 'that would', 'there had', 'there shall', 'there are', 'there has', 'these are', 'they had', 'they shall', 'they are', 'they have', 'this has', 'those are', 'it is', 'it was', 'was not', 'we had', 'we would have', 'we will', 'we are', 'we have', 'were not', 'what did', 'what shall', 'what are', 'what has', 'what have', 'when has', 'where did', 'where are', 'where has', 'where have', 'which has', 'who would', 'who would have', 'who shall', 'who are', 'who has', 'who have', 'why did', 'why are', 'why has', 'will not', 'would have', 'would not', 'you all', 'you had', 'you shall', 'you are', 'you have']\n"
     ]
    }
   ],
   "source": [
    "print(len(contraction_list))\n",
    "print(len(meaningfull_list))\n",
    "\n",
    "for word in meaningfull_list:\n",
    "  if (' / ' in word or \", \" in word):\n",
    "    position_to_split = meaningfull_list.index(word)\n",
    "    \n",
    "    word_to_process = re.sub(r' / ', \",\", word)\n",
    "    splitword = word_to_process.split(',')\n",
    "    length_split_word = len(splitword)\n",
    "    \n",
    "    meaningfull_list.remove(word)\n",
    "    meaningfull_list.insert((position_to_split ), splitword[0] ) # For simplicity lets add only 1st word.\n",
    "\n",
    "print(contraction_list)\n",
    "print(meaningfull_list)\n",
    "\n",
    "#print(len(contraction_list))\n",
    "#print(len(meaningfull_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2108
    },
    "colab_type": "code",
    "id": "TJschD_Gb19J",
    "outputId": "0611670e-982e-44af-986c-ddcb68e8f7cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'cause\": 'because',\n",
       " \"'s\": 'is',\n",
       " \"'tis\": 'it is',\n",
       " \"'twas\": 'it was',\n",
       " \"I'd\": 'I had',\n",
       " \"I'll\": 'I shall',\n",
       " \"I'm\": 'I am',\n",
       " \"I'm'a\": 'I am about to',\n",
       " \"I'm'o\": 'I am going to',\n",
       " \"I've\": 'I have',\n",
       " \"ain't\": 'am not',\n",
       " \"amn't\": 'am not',\n",
       " \"aren't\": 'are not',\n",
       " \"cain't\": 'cannot',\n",
       " \"can't\": 'cannot',\n",
       " \"could've\": 'could have',\n",
       " \"couldn't\": 'could not',\n",
       " \"couldn't've\": 'could not have',\n",
       " \"daren't\": 'dare not',\n",
       " \"daresn't\": 'dare not',\n",
       " \"dasn't\": 'dare not',\n",
       " \"didn't\": 'did not',\n",
       " \"doesn't\": 'does not',\n",
       " \"don't\": 'do not',\n",
       " \"e'er\": 'ever',\n",
       " \"everyone's\": 'everyone is',\n",
       " 'finna': 'fixing to',\n",
       " 'gimme': 'give me',\n",
       " \"gon't\": 'go not',\n",
       " 'gonna': 'going to',\n",
       " 'gotta': 'got to',\n",
       " \"hadn't\": 'had not',\n",
       " \"hasn't\": 'has not',\n",
       " \"haven't\": 'have not',\n",
       " \"he'd\": 'he had',\n",
       " \"he'll\": 'he shall',\n",
       " \"he's\": 'he has',\n",
       " \"he've\": 'he have',\n",
       " \"how'd\": 'how did',\n",
       " \"how'll\": 'how will',\n",
       " \"how're\": 'how are',\n",
       " \"how's\": 'how has',\n",
       " \"isn't\": 'is not',\n",
       " \"it'd\": 'it would',\n",
       " \"it'll\": 'it shall',\n",
       " \"it's\": 'it has',\n",
       " \"let's\": 'let us',\n",
       " \"may've\": 'may have',\n",
       " \"mayn't\": 'may not',\n",
       " \"might've\": 'might have',\n",
       " \"mightn't\": 'might not',\n",
       " \"must've\": 'must have',\n",
       " \"mustn't\": 'must not',\n",
       " \"mustn't've\": 'must not have',\n",
       " \"ne'er\": 'never',\n",
       " \"needn't\": 'need not',\n",
       " \"o'clock\": 'of the clock',\n",
       " \"o'er\": 'over',\n",
       " \"ol'\": 'old',\n",
       " \"oughtn't\": 'ought not',\n",
       " 'rarely': 'cannot',\n",
       " \"shalln't\": 'shall not',\n",
       " \"shan't\": 'shall not',\n",
       " \"she'd\": 'she had',\n",
       " \"she'll\": 'she shall',\n",
       " \"she's\": 'she has',\n",
       " \"should've\": 'should have',\n",
       " \"shouldn't\": 'should not',\n",
       " \"shouldn't've\": 'should not have',\n",
       " \"so're\": 'so are',\n",
       " \"somebody's\": 'somebody has',\n",
       " \"someone's\": 'someone has',\n",
       " \"something's\": 'something has',\n",
       " \"that'd\": 'that would',\n",
       " \"that'll\": 'that shall',\n",
       " \"that're\": 'that are',\n",
       " \"that's\": 'that has',\n",
       " \"there'd\": 'there had',\n",
       " \"there'll\": 'there shall',\n",
       " \"there're\": 'there are',\n",
       " \"there's\": 'there has',\n",
       " \"these're\": 'these are',\n",
       " \"they'd\": 'they had',\n",
       " \"they'll\": 'they shall',\n",
       " \"they're\": 'they are',\n",
       " \"they've\": 'they have',\n",
       " \"this's\": 'this has',\n",
       " \"those're\": 'those are',\n",
       " \"wasn't\": 'was not',\n",
       " \"we'd\": 'we had',\n",
       " \"we'd've\": 'we would have',\n",
       " \"we'll\": 'we will',\n",
       " \"we're\": 'we are',\n",
       " \"we've\": 'we have',\n",
       " \"weren't\": 'were not',\n",
       " \"what'd\": 'what did',\n",
       " \"what'll\": 'what shall',\n",
       " \"what're\": 'what are',\n",
       " \"what's\": 'what has',\n",
       " \"what've\": 'what have',\n",
       " \"when's\": 'when has',\n",
       " \"where'd\": 'where did',\n",
       " \"where're\": 'where are',\n",
       " \"where's\": 'where has',\n",
       " \"where've\": 'where have',\n",
       " \"which's\": 'which has',\n",
       " \"who'd\": 'who would',\n",
       " \"who'd've\": 'who would have',\n",
       " \"who'll\": 'who shall',\n",
       " \"who're\": 'who are',\n",
       " \"who's\": 'who has',\n",
       " \"who've\": 'who have',\n",
       " \"why'd\": 'why did',\n",
       " \"why're\": 'why are',\n",
       " \"why's\": 'why has',\n",
       " \"won't\": 'will not',\n",
       " \"would've\": 'would have',\n",
       " \"wouldn't\": 'would not',\n",
       " \"y'all\": 'you all',\n",
       " \"you'd\": 'you had',\n",
       " \"you'll\": 'you shall',\n",
       " \"you're\": 'you are',\n",
       " \"you've\": 'you have'}"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary = dict(zip(contraction_list, meaningfull_list))\n",
    "dictionary = {k: v for k,v in zip(contraction_list, meaningfull_list)}\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "coKf3ugeXKsB"
   },
   "outputs": [],
   "source": [
    "# Review the questions:\n",
    "def mappingWords(questions,dictionary):\n",
    "    return \" \".join([dictionary.get(w,w) for w in questions.split()])\n",
    "\n",
    "def review_questions(questions):\n",
    "  #questions = mappingWords(questions, dictionary)\n",
    "  questions = re.sub(r\"[^a-zA-Z0-9 ]\", \" \", questions)\n",
    "  questions = re.sub(r'[0-9]+', \"Number\", questions)\n",
    "  return questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gl-eBIl8XmaH"
   },
   "outputs": [],
   "source": [
    "question_list = []\n",
    "for i in range(len(train_data[\"question_text\"])):\n",
    "  question_list.append(review_questions(train_data[\"question_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cjmQ3hke1dFl",
    "outputId": "937ad03b-2019-44f4-e53e-be39aa87569d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How did Quebec nationalists see their province as a nation in the Numbers '"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaQSg74h1tK0"
   },
   "outputs": [],
   "source": [
    "# Save the data in .pickle format\n",
    "pickle_input = open(\"input_question_X.pickle\", \"wb\")\n",
    "pickle.dump(question_list, pickle_input)\n",
    "pickle_input.close()\n",
    "\n",
    "pickle_output = open(\"output_question_y.pickle\", \"wb\")\n",
    "pickle.dump(train_data[\"target\"], pickle_output)\n",
    "pickle_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0FJTs8xudz4D",
    "outputId": "25e170ca-96a3-4e09-a231-617998b5a91d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1HAHGC7SA-8Baljm1sQQc4Jk9IT-czCoG\n",
      "Uploaded file with ID 1eY5QXEMYowrJGwyYeyXQHVapdvkLyq1R\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file text file.\n",
    "uploaded = drive.CreateFile()\n",
    "uploaded.SetContentFile('input_question_X.pickle')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
    "\n",
    "uploaded_y = drive.CreateFile()\n",
    "uploaded_y.SetContentFile('output_question_y.pickle')\n",
    "uploaded_y.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded_y.get('id')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_vqzwLPYfzH-",
    "outputId": "28e33d44-6731-4439-8bc7-cc6308d506a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K    1% |▎                               | 10kB 24.8MB/s eta 0:00:01\r",
      "\u001b[K    2% |▋                               | 20kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K    3% |█                               | 30kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K    4% |█▎                              | 40kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K    5% |█▋                              | 51kB 3.8MB/s eta 0:00:01\r",
      "\u001b[K    6% |██                              | 61kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K    7% |██▎                             | 71kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K    8% |██▋                             | 81kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K    9% |███                             | 92kB 6.2MB/s eta 0:00:01\r",
      "\u001b[K    10% |███▎                            | 102kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K    11% |███▋                            | 112kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K    12% |████                            | 122kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K    13% |████▎                           | 133kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K    14% |████▋                           | 143kB 12.7MB/s eta 0:00:01\r",
      "\u001b[K    15% |█████                           | 153kB 12.6MB/s eta 0:00:01\r",
      "\u001b[K    16% |█████▎                          | 163kB 12.6MB/s eta 0:00:01\r",
      "\u001b[K    17% |█████▋                          | 174kB 13.3MB/s eta 0:00:01\r",
      "\u001b[K    18% |██████                          | 184kB 13.5MB/s eta 0:00:01\r",
      "\u001b[K    19% |██████▎                         | 194kB 13.4MB/s eta 0:00:01\r",
      "\u001b[K    20% |██████▋                         | 204kB 46.5MB/s eta 0:00:01\r",
      "\u001b[K    21% |███████                         | 215kB 14.6MB/s eta 0:00:01\r",
      "\u001b[K    22% |███████▎                        | 225kB 14.6MB/s eta 0:00:01\r",
      "\u001b[K    23% |███████▋                        | 235kB 14.8MB/s eta 0:00:01\r",
      "\u001b[K    24% |████████                        | 245kB 14.8MB/s eta 0:00:01\r",
      "\u001b[K    25% |████████▎                       | 256kB 14.9MB/s eta 0:00:01\r",
      "\u001b[K    26% |████████▋                       | 266kB 14.3MB/s eta 0:00:01\r",
      "\u001b[K    27% |█████████                       | 276kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K    29% |█████████▎                      | 286kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K    30% |█████████▋                      | 296kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K    31% |██████████                      | 307kB 15.0MB/s eta 0:00:01\r",
      "\u001b[K    32% |██████████▎                     | 317kB 53.4MB/s eta 0:00:01\r",
      "\u001b[K    33% |██████████▋                     | 327kB 53.3MB/s eta 0:00:01\r",
      "\u001b[K    34% |███████████                     | 337kB 53.8MB/s eta 0:00:01\r",
      "\u001b[K    35% |███████████▎                    | 348kB 48.5MB/s eta 0:00:01\r",
      "\u001b[K    36% |███████████▋                    | 358kB 49.0MB/s eta 0:00:01\r",
      "\u001b[K    37% |████████████                    | 368kB 57.7MB/s eta 0:00:01\r",
      "\u001b[K    38% |████████████▎                   | 378kB 57.7MB/s eta 0:00:01\r",
      "\u001b[K    39% |████████████▋                   | 389kB 58.1MB/s eta 0:00:01\r",
      "\u001b[K    40% |█████████████                   | 399kB 18.5MB/s eta 0:00:01\r",
      "\u001b[K    41% |█████████████▎                  | 409kB 17.7MB/s eta 0:00:01\r",
      "\u001b[K    42% |█████████████▋                  | 419kB 17.7MB/s eta 0:00:01\r",
      "\u001b[K    43% |██████████████                  | 430kB 17.7MB/s eta 0:00:01\r",
      "\u001b[K    44% |██████████████▎                 | 440kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K    45% |██████████████▋                 | 450kB 17.8MB/s eta 0:00:01\r",
      "\u001b[K    46% |███████████████                 | 460kB 17.7MB/s eta 0:00:01\r",
      "\u001b[K    47% |███████████████▎                | 471kB 17.8MB/s eta 0:00:01\r",
      "\u001b[K    48% |███████████████▋                | 481kB 17.8MB/s eta 0:00:01\r",
      "\u001b[K    49% |████████████████                | 491kB 17.7MB/s eta 0:00:01\r",
      "\u001b[K    50% |████████████████▎               | 501kB 51.8MB/s eta 0:00:01\r",
      "\u001b[K    51% |████████████████▋               | 512kB 55.1MB/s eta 0:00:01\r",
      "\u001b[K    52% |█████████████████               | 522kB 56.3MB/s eta 0:00:01\r",
      "\u001b[K    53% |█████████████████▎              | 532kB 56.9MB/s eta 0:00:01\r",
      "\u001b[K    54% |█████████████████▋              | 542kB 58.1MB/s eta 0:00:01\r",
      "\u001b[K    55% |██████████████████              | 552kB 62.4MB/s eta 0:00:01\r",
      "\u001b[K    57% |██████████████████▎             | 563kB 63.0MB/s eta 0:00:01\r",
      "\u001b[K    58% |██████████████████▋             | 573kB 63.1MB/s eta 0:00:01\r",
      "\u001b[K    59% |███████████████████             | 583kB 63.2MB/s eta 0:00:01\r",
      "\u001b[K    60% |███████████████████▎            | 593kB 63.8MB/s eta 0:00:01\r",
      "\u001b[K    61% |███████████████████▋            | 604kB 63.8MB/s eta 0:00:01\r",
      "\u001b[K    62% |████████████████████            | 614kB 67.8MB/s eta 0:00:01\r",
      "\u001b[K    63% |████████████████████▎           | 624kB 66.8MB/s eta 0:00:01\r",
      "\u001b[K    64% |████████████████████▋           | 634kB 68.1MB/s eta 0:00:01\r",
      "\u001b[K    65% |█████████████████████           | 645kB 68.7MB/s eta 0:00:01\r",
      "\u001b[K    66% |█████████████████████▎          | 655kB 67.5MB/s eta 0:00:01\r",
      "\u001b[K    67% |█████████████████████▋          | 665kB 51.8MB/s eta 0:00:01\r",
      "\u001b[K    68% |██████████████████████          | 675kB 51.7MB/s eta 0:00:01\r",
      "\u001b[K    69% |██████████████████████▎         | 686kB 52.0MB/s eta 0:00:01\r",
      "\u001b[K    70% |██████████████████████▋         | 696kB 52.6MB/s eta 0:00:01\r",
      "\u001b[K    71% |███████████████████████         | 706kB 51.8MB/s eta 0:00:01\r",
      "\u001b[K    72% |███████████████████████▎        | 716kB 52.1MB/s eta 0:00:01\r",
      "\u001b[K    73% |███████████████████████▋        | 727kB 52.4MB/s eta 0:00:01\r",
      "\u001b[K    74% |████████████████████████        | 737kB 51.9MB/s eta 0:00:01\r",
      "\u001b[K    75% |████████████████████████▎       | 747kB 52.6MB/s eta 0:00:01\r",
      "\u001b[K    76% |████████████████████████▋       | 757kB 36.1MB/s eta 0:00:01\r",
      "\u001b[K    77% |████████████████████████▉       | 768kB 40.4MB/s eta 0:00:01\r",
      "\u001b[K    78% |█████████████████████████▏      | 778kB 40.3MB/s eta 0:00:01\r",
      "\u001b[K    79% |█████████████████████████▌      | 788kB 39.5MB/s eta 0:00:01\r",
      "\u001b[K    80% |█████████████████████████▉      | 798kB 39.3MB/s eta 0:00:01\r",
      "\u001b[K    81% |██████████████████████████▏     | 808kB 38.9MB/s eta 0:00:01\r",
      "\u001b[K    82% |██████████████████████████▌     | 819kB 38.9MB/s eta 0:00:01\r",
      "\u001b[K    83% |██████████████████████████▉     | 829kB 38.9MB/s eta 0:00:01\r",
      "\u001b[K    85% |███████████████████████████▏    | 839kB 39.2MB/s eta 0:00:01\r",
      "\u001b[K    86% |███████████████████████████▌    | 849kB 38.9MB/s eta 0:00:01\r",
      "\u001b[K    87% |███████████████████████████▉    | 860kB 54.4MB/s eta 0:00:01\r",
      "\u001b[K    88% |████████████████████████████▏   | 870kB 59.5MB/s eta 0:00:01\r",
      "\u001b[K    89% |████████████████████████████▌   | 880kB 61.2MB/s eta 0:00:01\r",
      "\u001b[K    90% |████████████████████████████▉   | 890kB 62.6MB/s eta 0:00:01\r",
      "\u001b[K    91% |█████████████████████████████▏  | 901kB 63.2MB/s eta 0:00:01\r",
      "\u001b[K    92% |█████████████████████████████▌  | 911kB 65.0MB/s eta 0:00:01\r",
      "\u001b[K    93% |█████████████████████████████▉  | 921kB 65.7MB/s eta 0:00:01\r",
      "\u001b[K    94% |██████████████████████████████▏ | 931kB 67.1MB/s eta 0:00:01\r",
      "\u001b[K    95% |██████████████████████████████▌ | 942kB 67.5MB/s eta 0:00:01\r",
      "\u001b[K    96% |██████████████████████████████▉ | 952kB 67.6MB/s eta 0:00:01\r",
      "\u001b[K    97% |███████████████████████████████▏| 962kB 75.9MB/s eta 0:00:01\r",
      "\u001b[K    98% |███████████████████████████████▌| 972kB 76.1MB/s eta 0:00:01\r",
      "\u001b[K    99% |███████████████████████████████▉| 983kB 73.1MB/s eta 0:00:01\r",
      "\u001b[K    100% |████████████████████████████████| 993kB 23.4MB/s \n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "downloaded_input = drive.CreateFile({'id': '1HAHGC7SA-8Baljm1sQQc4Jk9IT-czCoG'})\n",
    "downloaded_input.GetContentFile('input_question_X.pickle')\n",
    "\n",
    "downloaded_output = drive.CreateFile({'id': '1eY5QXEMYowrJGwyYeyXQHVapdvkLyq1R'})\n",
    "downloaded_output.GetContentFile('output_question_y.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPUKXEX4a2zy"
   },
   "outputs": [],
   "source": [
    "# To find all the punctuations.\n",
    "checkpunctuation = []\n",
    "length = int(len(question_list))\n",
    "for i in range(length):\n",
    "  checkpunctuation.append( re.findall(r\"[^a-zA-Z ]\", question_list[i]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o5Dz6g_7wwNr",
    "outputId": "32d2c34a-7160-45d1-bb03-f9e81fa3ee1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting list into dataframe, to check if it is empty or not!\n",
    "punctuationdf = pd.DataFrame({ \"punctuation\" : checkpunctuation })\n",
    "punctuationdf[\"punctuation\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mo6cIu3AjYV5",
    "outputId": "843b289d-4462-491b-a900-732c8083320b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# To print punctuations from top 100 questions.\n",
    "myCheckSet = set()\n",
    "for i in range(len(checkpunctuation)):\n",
    "\n",
    "  for j in range(len(checkpunctuation[i])):\n",
    "    myset.add(checkpunctuation[i][j])\n",
    "print(myCheckSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTZI9EBpdNAk"
   },
   "source": [
    "So, now, there are no punctuation marks in whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "-AQCvXqrWzeH",
    "outputId": "eca2bad2-2100-407d-add8-ea7362939e70"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAERCAYAAACpRtp7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc7vM4+HiKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check out the skewed data\n",
    "get_pickle_output = open(\"output_question_y.pickle\", \"rb\")\n",
    "y = pickle.load(get_pickle_output)\n",
    "\n",
    "unique_target = pd.value_counts(y, sort = True).sort_index()\n",
    "unique_target.plot(kind = 'bar')\n",
    "plot.title(\"Quora insincere Target class\")\n",
    "plot.xlabel(\"Target\")\n",
    "plot.ylabel(\"Questions\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fxKTYKyjdX6a",
    "outputId": "14e951f9-9794-4d64-b296-96e096726da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Archive:  embeddings.zip\n",
      "   creating: GoogleNews-vectors-negative300/\n",
      "   creating: glove.840B.300d/\n",
      "   creating: paragram_300_sl999/\n",
      "   creating: wiki-news-300d-1M/\n",
      "  inflating: glove.840B.300d/glove.840B.300d.txt  \n",
      "  inflating: GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \n",
      "  inflating: wiki-news-300d-1M/wiki-news-300d-1M.vec  \n",
      "  inflating: paragram_300_sl999/README.txt  \n",
      "  inflating: paragram_300_sl999/paragram_300_sl999.txt  \n"
     ]
    }
   ],
   "source": [
    "# Let's try different embeddings.\n",
    "%cd /content\n",
    "!unzip embeddings.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kF1nSKj2dXzN",
    "outputId": "21bbffde-c7e1-49f4-849a-0c7f32af4e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!bash -c 'mv glove.840B.300d /content/Kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XLxkpJ_mdZSH",
    "outputId": "e1885f4a-1d31-443a-91e1-aad4510f4ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Kaggle\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0mgN0tY3VHV"
   },
   "source": [
    "Let's import GloVe\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zt25kMte0gs4"
   },
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding='utf8')\n",
    "    embedding_index = {}\n",
    "    print(\"Opened!\")\n",
    "    for line in f:\n",
    "        splitLine = line.split(' ')\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        embedding_index[word] = embedding\n",
    "        \n",
    "    print(\"Done.\",len(embedding_index),\" words loaded!\")\n",
    "    return embedding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5_Oa4WOF0xKn",
    "outputId": "078aa526-30c3-4f22-d077-17c99979be99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Opened!\n",
      "Done. 2196016  words loaded!\n"
     ]
    }
   ],
   "source": [
    "gloveFile = 'glove.840B.300d/glove.840B.300d.txt'\n",
    "embedding_index = loadGloveModel(gloveFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ABnNtLllc6f"
   },
   "outputs": [],
   "source": [
    "# First of all, lets just plug the data directly into our learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ifJBpAkN2h6X",
    "outputId": "1765a13b-cee2-43f0-8987-eb25098aab47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "# Get the training X, and y data.\n",
    "get_pickle_X = open(\"input_question_X.pickle\", \"rb\")\n",
    "X= pickle.load(get_pickle_X)\n",
    "\n",
    "get_pickle_y = open(\"output_question_y.pickle\", \"rb\")\n",
    "y= pickle.load(get_pickle_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeknrudBPq0m"
   },
   "outputs": [],
   "source": [
    "'''# Split the  data into trainig, testing, and cross validation.\n",
    "def split_data(data):\n",
    "  # my data to be splitted.\n",
    "  split_index = int(len(train_data) * 0.9)\n",
    "  X_train = X[:split_index]\n",
    "  y_train = y[:split_index]\n",
    "  \n",
    "  X_val = X[split_index:]\n",
    "  y_val = y[split_index:]\n",
    "  \n",
    "  return X_train, X_val, y_train, y_val \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3aXK8CCPta0"
   },
   "outputs": [],
   "source": [
    "data = [X, y]\n",
    "\n",
    "#X_train, X_val, y_train, y_val = split_data(data)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.05)\n",
    "\n",
    "#print(np.array((X)).shape)\n",
    "#print(np.array((X_train)).shape)\n",
    "#print(np.array((X_val)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4XF-5frjnl6"
   },
   "outputs": [],
   "source": [
    "# process test question_text column.\n",
    "question_list_test = []\n",
    "for i in range(len(test_data[\"question_text\"])):\n",
    "    question_list_test.append(review_questions(test_data[\"question_text\"][i]))\n",
    "\n",
    "X_test = question_list_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRhxKtIAmdHy"
   },
   "outputs": [],
   "source": [
    "# Generate the text sequence for RNN model\n",
    "np.random.seed(1000)\n",
    "NUM_MOST_FREQ_WORDS_TO_INCLUDE = 100000\n",
    "MAX_REVIEW_LENGTH_FOR_KERAS_RNN = 80           # Input for keras.\n",
    "embedding_vector_length = 32\n",
    "\n",
    "all_quesion = X_train + X_val\n",
    "\n",
    "tokenizer = Tokenizer(num_words = NUM_MOST_FREQ_WORDS_TO_INCLUDE)\n",
    "tokenizer.fit_on_texts(all_quesion)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#tokenising train data\n",
    "train_question_tokenized = tokenizer.texts_to_sequences(X_train)      \n",
    "X_train = pad_sequences(train_question_tokenized, maxlen = MAX_REVIEW_LENGTH_FOR_KERAS_RNN)          # len(X_train) x 50\n",
    "\n",
    "#tokenising validation data\n",
    "val_question_tokenized = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(val_question_tokenized, maxlen = MAX_REVIEW_LENGTH_FOR_KERAS_RNN)               # len(X_val) X 50 \n",
    "\n",
    "#tokenizing test data\n",
    "#test_question_tokenized = tokenizer.texts_to_sequences(X_test)\n",
    "#X_test = pad_sequences(test_question_tokenized, maxlen = MAX_REVIEW_LENGTH_FOR_KERAS_RNN)\n",
    "\n",
    "save_tokenizer = open(\"Tokenizer.pickle\", \"wb\")\n",
    "pickle.dump(tokenizer, save_tokenizer)\n",
    "save_tokenizer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mu4-jbnGhcOx",
    "outputId": "e433fd1a-a82b-4987-cf1d-2cbd35ae666a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1Xat5JsRVZz9BgPKICyAaDZ7ZFEeRxZbt\n"
     ]
    }
   ],
   "source": [
    "# 2. Create & upload a file text file.\n",
    "uploaded = drive.CreateFile()\n",
    "uploaded.SetContentFile('Tokenizer.pickle')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wkPNWHK64ekd",
    "outputId": "936804d7-db41-4367-92c4-cc986468cc3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181933 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPM02T984ff3"
   },
   "outputs": [],
   "source": [
    "# Now, we need to create embedding matrix.\n",
    "EMBEDDING_DIM = 300\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tq0X9NQYqB9l",
    "outputId": "8a3d44a3-3b9f-4de4-970b-001b59b9e495"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"embedding_matrix\": shape (181936, 300), type \"<f8\">"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file = h5py.File(\"embedding_matrix.h5\")\n",
    "h5file.create_dataset(\"embedding_matrix\", data=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VU2stWcT8uxx",
    "outputId": "c9cc36e0-7142-449b-aa29-501c91424d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/Kaggle'\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "# save embedding matrix in .pickle format.\n",
    "%cd /content/Kaggle\n",
    "my_embedd = open(\"glove_840B_300D_embedding.pickle\", \"wb\")\n",
    "pickle.dump(embedding_matrix, my_embedd)\n",
    "my_embedd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBveElLyvdVf"
   },
   "outputs": [],
   "source": [
    "get_embedd = open(\"glove_840B_300D_embedding.pickle\", \"rb\")\n",
    "embedding_matrix = pickle.load(get_embedd)\n",
    "get_embedd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z7p4kZzvhvx_",
    "outputId": "d931908e-a53c-456b-ce4d-02cf8e187762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 16YeNHHCVABMfAzbWnqxss0GPD6mMRoz-\n"
     ]
    }
   ],
   "source": [
    "# 2. Create & upload a file text file.\n",
    "uploaded = drive.CreateFile()\n",
    "uploaded.SetContentFile('glove_840B_300D_embedding.pickle')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t6jU78Ufmj06"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "downloaded_embedd = drive.CreateFile({'id': '16YeNHHCVABMfAzbWnqxss0GPD6mMRoz-'})\n",
    "downloaded_embedd.GetContentFile('glove_840B_300D_embedding.pickle')\n",
    "\n",
    "my_embedd = open(\"glove_840B_300D_embedding.pickle\", \"rb\")\n",
    "embedding_matrix = pickle.load(my_embedd)\n",
    "my_embedd.close() ooooo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKijEir-nRGh"
   },
   "outputs": [],
   "source": [
    "def RNNModel():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                      input_length=MAX_REVIEW_LENGTH_FOR_KERAS_RNN, trainable=False) )\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "    model.add(CuDNNGRU(100, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(CuDNNGRU(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "22mNApxvpTot",
    "outputId": "92cf1a0f-9a50-4768-f370-0c50c5f7123f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 459s 370us/step - loss: 0.1191 - acc: 0.9531 - val_loss: 0.1142 - val_acc: 0.9558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe59cedf780>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel()\n",
    "model.fit(X_train, y_train, batch_size=64, epochs = 1, validation_data=[X_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIXOza0UpZlb"
   },
   "outputs": [],
   "source": [
    "my_model_save = open(\"1st_model.pickle\", \"wb\")\n",
    "pickle.dump('model.h5', my_model_save)\n",
    "my_model_save.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "dgnZNeqh1tBT",
    "outputId": "bf38ff67-ec25-4aaa-ebb4-739af6b6d1e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67515016],\n",
       "       [0.21627244],\n",
       "       [0.00418785],\n",
       "       ...,\n",
       "       [0.00772439],\n",
       "       [0.3626201 ],\n",
       "       [0.00260632]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_prediction = model.predict(X_val)\n",
    "y_val_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Goct4ypX8_e5",
    "outputId": "8c75a006-ac8c-458e-cbc0-34df438ec10b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00930867],\n",
       "       [0.00446617],\n",
       "       [0.00388651],\n",
       "       ...,\n",
       "       [0.00183088],\n",
       "       [0.02422588],\n",
       "       [0.46029472]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_prediction = model.predict(X_train)\n",
    "y_train_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDGOyeurC_6z"
   },
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTpKNwbw3Q0G"
   },
   "outputs": [],
   "source": [
    "def get_best_threshold_value(y_val, y_val_prediction, threshold_list):\n",
    "  best_f1 = 0\n",
    "  best_threshold_value = threshold_list[0]\n",
    "  \n",
    "  for threshold in threshold_list:\n",
    "    score = metrics.f1_score(y_val, (y_val_prediction > threshold).astype(int))\n",
    "\n",
    "    # We need our f1_score to be maximum as possible.\n",
    "    if(score > best_f1):\n",
    "      best_f1 = score\n",
    "      best_threshold_value = threshold\n",
    "  \n",
    "  return best_threshold_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGXz7Vo92FeL"
   },
   "outputs": [],
   "source": [
    "def F1_Score(y_val, y_val_prediction):\n",
    "  # Lets calculate the threshold value for f1 score.\n",
    "  threshold_list = np.arange(0.2, 0.701, 0.02)\n",
    "\n",
    "  best_threshold_value = get_best_threshold_value(y_val, y_val_prediction, threshold_list)\n",
    "\n",
    "  # Use sklearn to get the f1score, using this best threshold value.\n",
    "  f1score = metrics.f1_score(y_val, (y_val_prediction > best_threshold_value).astype(int))\n",
    "  \n",
    "  return f1score, best_threshold_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3403
    },
    "colab_type": "code",
    "id": "7MvbiwzHw0go",
    "outputId": "d4756e59-d44f-4564-961d-47d9ebd5bd16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_LSTM_CONV_1-conv-32-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           82944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,741,705\n",
      "Trainable params: 161,505\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1044s 841us/step - loss: 0.1181 - acc: 0.9536 - val_loss: 0.1086 - val_acc: 0.9567\n",
      "Model_LSTM_CONV_2-conv-32-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           82944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,744,809\n",
      "Trainable params: 164,609\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 733s 591us/step - loss: 0.1192 - acc: 0.9529 - val_loss: 0.1098 - val_acc: 0.9558\n",
      "Model_LSTM_CONV_1-conv-64-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           99328     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,786,921\n",
      "Trainable params: 206,721\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 935s 754us/step - loss: 0.1163 - acc: 0.9539 - val_loss: 0.1067 - val_acc: 0.9579\n",
      "Model_LSTM_CONV_2-conv-64-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           99328     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,799,273\n",
      "Trainable params: 219,073\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 758s 611us/step - loss: 0.1179 - acc: 0.9537 - val_loss: 0.1080 - val_acc: 0.9571\n",
      "Model_LSTM_CONV_1-conv-128-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,877,353\n",
      "Trainable params: 297,153\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1099s 886us/step - loss: 0.1159 - acc: 0.9543 - val_loss: 0.1098 - val_acc: 0.9585\n",
      "Model_LSTM_CONV_2-conv-128-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,926,633\n",
      "Trainable params: 346,433\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 818s 659us/step - loss: 0.1183 - acc: 0.9534 - val_loss: 0.1103 - val_acc: 0.9559\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "dense_layers = [0]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "#drop_out = [0.2, 0.5]\n",
    "\n",
    "# Clearing tensorflow session right before creating the model\n",
    "# https://stackoverflow.com/questions/50479021/keras-callback-causes-error-you-must-feed-a-value-for-placeholder-tensor-conv/52239671#52239671\n",
    "K.clear_session()\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "      print(NAME)\n",
    "\n",
    "      model = Sequential()\n",
    "\n",
    "      model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "          input_length=MAX_REVIEW_LENGTH_FOR_KERAS_RNN, trainable=False) )\n",
    "\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "      model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      for l in range(conv - 1):\n",
    "        model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "        model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      model.add( CuDNNLSTM(128, return_sequences=True))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add( CuDNNLSTM(64, return_sequences=False))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Flatten())\n",
    "\n",
    "      for n in range(dense):\n",
    "        model.add(Dense(filters, activation = \"relu\"))\n",
    "\n",
    "      model.add(Dense(1, activation = \"sigmoid\"))\n",
    "      \n",
    "      model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "      model.summary()\n",
    "      model.fit(X_train, y_train, batch_size = 32, epochs = 1, validation_data = [X_val, y_val] )\n",
    "\n",
    "      model.save(\"{}.h5\".format(NAME))\n",
    "      \n",
    "      K.clear_session()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "QS_xyE-8JxVA",
    "outputId": "59bde660-b237-4fa3-efe2-a4ee801e5f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1XcR0Gr7GXKcYkWwJ1hJd63aV_nULFyht\n",
      "Uploaded file with ID 1ws6EwnFLDW_MLcIZE8481dpYEj-F8f3f\n",
      "Uploaded file with ID 1MU9kmIBO_4MNLL57WI-2TngQTsGKyF0g\n",
      "Uploaded file with ID 1B_bVHXM1f1MqztfKTLTEIKVSQhTojP-7\n",
      "Uploaded file with ID 1EGTDXDs8U2LIyNESsMpnptTmtJOLhpJP\n",
      "Uploaded file with ID 1SzhmFsq6zVgjyxn90kEI-EWGcqAUoG7t\n"
     ]
    }
   ],
   "source": [
    "# Save models in google drive.\n",
    "dense_layers = [0]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "#drop_out = [0.2, 0.5]\n",
    "\n",
    "# Clearing tensorflow session right before creating the model\n",
    "# https://stackoverflow.com/questions/50479021/keras-callback-causes-error-you-must-feed-a-value-for-placeholder-tensor-conv/52239671#52239671\n",
    "K.clear_session()\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "      #print(NAME)\n",
    "\n",
    "      # 2. Create & upload a file text file.\n",
    "      uploaded = drive.CreateFile()\n",
    "      uploaded.SetContentFile('{}.h5'.format(NAME))\n",
    "      uploaded.Upload()\n",
    "      print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qCwuit12Wf1a",
    "outputId": "95c7f70e-686b-4135-fd5b-d5f460cafb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4h4uc03BUT9K",
    "outputId": "0e5cd8f6-f96e-4d7f-b778-af68d53680ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Kaggle\n"
     ]
    }
   ],
   "source": [
    "# upload models from google drive.\n",
    "# Clearing tensorflow session right before creating the model\n",
    "# https://stackoverflow.com/questions/50479021/keras-callback-causes-error-you-must-feed-a-value-for-placeholder-tensor-conv/52239671#52239671\n",
    "#K.clear_session()\n",
    "\n",
    "id = [ '1XcR0Gr7GXKcYkWwJ1hJd63aV_nULFyht',\n",
    "       '1ws6EwnFLDW_MLcIZE8481dpYEj-F8f3f',\n",
    "       '1MU9kmIBO_4MNLL57WI-2TngQTsGKyF0g',\n",
    "       '1B_bVHXM1f1MqztfKTLTEIKVSQhTojP-7',\n",
    "       '1EGTDXDs8U2LIyNESsMpnptTmtJOLhpJP',\n",
    "       '1SzhmFsq6zVgjyxn90kEI-EWGcqAUoG7t' ]\n",
    "\n",
    "\n",
    "dense_layers = [0]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "#drop_out = [0.2, 0.5]\n",
    "%cd /content/Kaggle\n",
    "\n",
    "# Clearing tensorflow session right before creating the model\n",
    "# https://stackoverflow.com/questions/50479021/keras-callback-causes-error-you-must-feed-a-value-for-placeholder-tensor-conv/52239671#52239671\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "      for i in id:\n",
    "        # 3. Load a file by ID and print its contents.\n",
    "        downloaded = drive.CreateFile({'id': i})\n",
    "        downloaded.GetContentFile(\"{}.h5\".format(NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "VoCdeSEMKe2i",
    "outputId": "31fa76aa-b7ce-46d1-ab5e-5864c6a76aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_LSTM_CONV_1-conv-32-layer-0-dense-> 0.5119033232628399 -> 0.22\n",
      "Model_LSTM_CONV_2-conv-32-layer-0-dense-> 0.5119033232628399 -> 0.22\n",
      "Model_LSTM_CONV_1-conv-64-layer-0-dense-> 0.5119033232628399 -> 0.22\n",
      "Model_LSTM_CONV_2-conv-64-layer-0-dense-> 0.5119033232628399 -> 0.22\n",
      "Model_LSTM_CONV_1-conv-128-layer-0-dense-> 0.5119033232628399 -> 0.22\n",
      "Model_LSTM_CONV_2-conv-128-layer-0-dense-> 0.5119033232628399 -> 0.22\n"
     ]
    }
   ],
   "source": [
    "dense_layers = [0]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      uploadmodel = load_model('{}.h5'.format(NAME))\n",
    "      y_val_prediction = uploadmodel.predict(X_val)\n",
    "            \n",
    "      f1_score, best_threshold_value = F1_Score(y_val, y_val_prediction)\n",
    "      print('{}-> {} -> {}'.format(NAME, f1_score, best_threshold_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vky6B6L4tVqs"
   },
   "source": [
    "F1_score for x_validation comes out to be around 0.51, with 0 dense layer, despite having 32, 64, 128 layers or 1 o2 convolutional layer.<Br/>\n",
    "Let's build model with 1 dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3607
    },
    "colab_type": "code",
    "id": "rM3vpUeLm6Xs",
    "outputId": "5a39eb08-220e-485d-f0d4-e8e54e013f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_LSTM_CONV_1-conv-32-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           82944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 54,743,753\n",
      "Trainable params: 163,553\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 977s 787us/step - loss: 0.1176 - acc: 0.9538 - val_loss: 0.1095 - val_acc: 0.9570\n",
      "Model_LSTM_CONV_2-conv-32-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           82944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 54,746,857\n",
      "Trainable params: 166,657\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 747s 602us/step - loss: 0.1187 - acc: 0.9533 - val_loss: 0.1123 - val_acc: 0.9554\n",
      "Model_LSTM_CONV_1-conv-64-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           99328     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,791,081\n",
      "Trainable params: 210,881\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 912s 735us/step - loss: 0.1169 - acc: 0.9539 - val_loss: 0.1099 - val_acc: 0.9564\n",
      "Model_LSTM_CONV_2-conv-64-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           99328     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,803,433\n",
      "Trainable params: 223,233\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 772s 622us/step - loss: 0.1179 - acc: 0.9533 - val_loss: 0.1094 - val_acc: 0.9568\n",
      "Model_LSTM_CONV_1-conv-128-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 54,885,737\n",
      "Trainable params: 305,537\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1108s 893us/step - loss: 0.1167 - acc: 0.9541 - val_loss: 0.1095 - val_acc: 0.9574\n",
      "Model_LSTM_CONV_2-conv-128-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 54,935,017\n",
      "Trainable params: 354,817\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 841s 678us/step - loss: 0.1186 - acc: 0.9532 - val_loss: 0.1105 - val_acc: 0.9562\n"
     ]
    }
   ],
   "source": [
    "# Model with 1 dense layer.\n",
    "dense_layers = [1]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "# Clearing tensorflow session right before creating the model\n",
    "K.clear_session()\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "      print(NAME)\n",
    "\n",
    "      model = Sequential()\n",
    "\n",
    "      model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "          input_length=MAX_REVIEW_LENGTH_FOR_KERAS_RNN, trainable=False) )\n",
    "\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "      model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      for l in range(conv - 1):\n",
    "        model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "        model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      model.add( CuDNNLSTM(128, return_sequences=True))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add( CuDNNLSTM(64, return_sequences=False))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Flatten())\n",
    "\n",
    "      for n in range(dense):\n",
    "        model.add(Dense(filters, activation = \"relu\"))\n",
    "\n",
    "      model.add(Dense(1, activation = \"sigmoid\"))\n",
    "      \n",
    "      model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "      model.summary()\n",
    "      model.fit(X_train, y_train, batch_size = 32, epochs = 1, validation_data = [X_val, y_val] )\n",
    "\n",
    "      model.save(\"{}.h5\".format(NAME))\n",
    "      \n",
    "      K.clear_session()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "4RYs-LcVu97V",
    "outputId": "3ada9b7b-3e57-4154-8125-7444cafad24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1fMOytiMB4a-ngi8CXB4XSBD3DeHZILg9\n",
      "Uploaded file with ID 1qTZ1ix5tm-zrCWDPe0I8BQnTejZF0YcD\n",
      "Uploaded file with ID 1Q7oTH13l-yn7TIrhb4rJW8L2KdN-mmzm\n",
      "Uploaded file with ID 1OQWAX5eAH-j-lomAXYgCxIJthzVzgIZQ\n",
      "Uploaded file with ID 1T4tivn-pnXD_i3pqO0P5xvaqPvyBM6hy\n",
      "Uploaded file with ID 1GG5uXRESHsBOjyo_6sltZfBHrB_RY9gX\n"
     ]
    }
   ],
   "source": [
    "# Save models in google drive.\n",
    "\n",
    "# saving the model in google drive\n",
    "dense_layers = [1]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      # 2. Create & upload a file text file.\n",
    "      uploaded = drive.CreateFile()\n",
    "      uploaded.SetContentFile('{}.h5'.format(NAME))\n",
    "      uploaded.Upload()\n",
    "      print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "cikCL382GmGE",
    "outputId": "aa151a72-0759-412e-a042-8934d1033f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_LSTM_CONV_1-conv-32-layer-1-dense-> 0.6512166859791425 -> 0.35999999999999993\n",
      "Model_LSTM_CONV_2-conv-32-layer-1-dense-> 0.6415689810640216 -> 0.35999999999999993\n",
      "Model_LSTM_CONV_1-conv-64-layer-1-dense-> 0.6570338689168882 -> 0.24\n",
      "Model_LSTM_CONV_2-conv-64-layer-1-dense-> 0.6494880938686299 -> 0.33999999999999997\n",
      "Model_LSTM_CONV_1-conv-128-layer-1-dense-> 0.6496032189560746 -> 0.3799999999999999\n",
      "Model_LSTM_CONV_2-conv-128-layer-1-dense-> 0.6430890538033395 -> 0.35999999999999993\n"
     ]
    }
   ],
   "source": [
    "#Calculate f1 score of validation data of each models.\n",
    "dense_layers = [1]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      uploadmodel = load_model('{}.h5'.format(NAME))\n",
    "      y_val_prediction = uploadmodel.predict(X_val)\n",
    "            \n",
    "      f1_score, best_threshold_value = F1_Score(y_val, y_val_prediction)\n",
    "      print('{}-> {} -> {}'.format(NAME, f1_score, best_threshold_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-yuwq6x1IH0T"
   },
   "source": [
    "So, adding one more dense layer, does make a huge difference, where f1 score jumps from 0.51 to 0.65. <Br/>\n",
    "In particular, with 1 convolution, and 64 layers comes out to be the best.\n",
    "First, Let's add one more dense layer, after that, we will try to increase the layer size.\n",
    "In general, with 1 convolution, f1 score is coming out to be the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3811
    },
    "colab_type": "code",
    "id": "o6j_WwpdIGPJ",
    "outputId": "8e49515b-9d57-4ef9-b1ea-67b54f091904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_LSTM_CONV_1-conv-32-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           82944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 54,744,809\n",
      "Trainable params: 164,609\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1073s 864us/step - loss: 0.1188 - acc: 0.9533 - val_loss: 0.1109 - val_acc: 0.9562\n",
      "Model_LSTM_CONV_2-conv-32-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           82944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 54,747,913\n",
      "Trainable params: 167,713\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 777s 626us/step - loss: 0.1192 - acc: 0.9529 - val_loss: 0.1108 - val_acc: 0.9571\n",
      "Model_LSTM_CONV_1-conv-64-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           99328     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,795,241\n",
      "Trainable params: 215,041\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1121s 903us/step - loss: 0.1174 - acc: 0.9536 - val_loss: 0.1094 - val_acc: 0.9574\n",
      "Model_LSTM_CONV_2-conv-64-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           99328     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,807,593\n",
      "Trainable params: 227,393\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 797s 642us/step - loss: 0.1194 - acc: 0.9529 - val_loss: 0.1112 - val_acc: 0.9563\n",
      "Model_LSTM_CONV_1-conv-128-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 40, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 54,902,249\n",
      "Trainable params: 322,049\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1166s 940us/step - loss: 0.1169 - acc: 0.9539 - val_loss: 0.1086 - val_acc: 0.9578\n",
      "Model_LSTM_CONV_2-conv-128-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 20, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                49664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 54,951,529\n",
      "Trainable params: 371,329\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 875s 705us/step - loss: 0.1195 - acc: 0.9528 - val_loss: 0.1114 - val_acc: 0.9568\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Model with 1 dense layer.\n",
    "\n",
    "dense_layers = [2]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "# Clearing tensorflow session right before creating the model\n",
    "K.clear_session()\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "      print(NAME)\n",
    "\n",
    "      model = Sequential()\n",
    "\n",
    "      model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "          input_length=MAX_REVIEW_LENGTH_FOR_KERAS_RNN, trainable=False) )\n",
    "\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "      model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      for l in range(conv - 1):\n",
    "        model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "        model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      model.add( CuDNNLSTM(128, return_sequences=True))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add( CuDNNLSTM(64, return_sequences=False))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Flatten())\n",
    "\n",
    "      for n in range(dense):\n",
    "        model.add(Dense(filters, activation = \"relu\"))\n",
    "\n",
    "      model.add(Dense(1, activation = \"sigmoid\"))\n",
    "      \n",
    "      model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "      model.summary()\n",
    "      model.fit(X_train, y_train, batch_size = 32, epochs = 1, validation_data = [X_val, y_val] )\n",
    "\n",
    "      model.save(\"{}.h5\".format(NAME))\n",
    "      \n",
    "      K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ylCE_GWHHqWn",
    "outputId": "094e4fb1-f90d-4f3f-d822-39a0229afc76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 18-djnHxQENF1MHiTF7b-u57O4iYNH5v3\n",
      "Uploaded file with ID 16uJqIRTzFx8DsEqWw0ham7vO7QwWFk4-\n",
      "Uploaded file with ID 1Yh0_u90lSsrHXGD93ByJ4PTWuxAlepDy\n",
      "Uploaded file with ID 1gtuHf8_pG1T-xx7H_I2RPMO7efTK6UFO\n",
      "Uploaded file with ID 1LPY7GRR6ESXJFz0rd1Zv5ZbpcTSvEivk\n",
      "Uploaded file with ID 1XCXwv-sBv690QIBazfL01bj1fkuqYOf9\n"
     ]
    }
   ],
   "source": [
    "# Save models in google drive.\n",
    "\n",
    "dense_layers = [2]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      # 2. Create & upload a file text file.\n",
    "      uploaded = drive.CreateFile()\n",
    "      uploaded.SetContentFile('{}.h5'.format(NAME))\n",
    "      uploaded.Upload()\n",
    "      print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "pytdNeyIgMrk",
    "outputId": "007fb167-5c9c-435b-b652-c915effa4822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_LSTM_CONV_1-conv-32-layer-2-dense-> 0.64423646487383 -> 0.31999999999999995\n",
      "Model_LSTM_CONV_2-conv-32-layer-2-dense-> 0.6399613899613898 -> 0.35999999999999993\n",
      "Model_LSTM_CONV_1-conv-64-layer-2-dense-> 0.6468472788300168 -> 0.3799999999999999\n",
      "Model_LSTM_CONV_2-conv-64-layer-2-dense-> 0.6430529663340279 -> 0.31999999999999995\n",
      "Model_LSTM_CONV_1-conv-128-layer-2-dense-> 0.6513427934795355 -> 0.35999999999999993\n",
      "Model_LSTM_CONV_2-conv-128-layer-2-dense-> 0.6460076905677449 -> 0.33999999999999997\n"
     ]
    }
   ],
   "source": [
    "#Calculate f1 score of validation data of each models.\n",
    "\n",
    "dense_layers = [2]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_LSTM_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      uploadmodel = load_model('{}.h5'.format(NAME))\n",
    "      y_val_prediction = uploadmodel.predict(X_val)\n",
    "            \n",
    "      f1_score, best_threshold_value = F1_Score(y_val, y_val_prediction)\n",
    "      print('{}-> {} -> {}'.format(NAME, f1_score, best_threshold_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRt7wwlHhyDX"
   },
   "source": [
    "So, adding one more dense layer, did not make much difference.\n",
    "We will continue with only one dense layer.<Br>\n",
    "  So, our model for LSTM will be -> Model_LSTM_CONV_1-conv-64-layer-1-dense with f1 score of 0.6570338689168882, with threshold of 0.24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3403
    },
    "colab_type": "code",
    "id": "qIDlWvD5gaW8",
    "outputId": "06e0c638-8438-4943-cc08-051c7e73a3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_GRU_CONV_1-conv-32-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 128)           62208     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,708,553\n",
      "Trainable params: 128,353\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1033s 832us/step - loss: 0.1188 - acc: 0.9532 - val_loss: 0.1115 - val_acc: 0.9560\n",
      "Model_GRU_CONV_2-conv-32-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 20, 128)           62208     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,711,657\n",
      "Trainable params: 131,457\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 732s 590us/step - loss: 0.1199 - acc: 0.9524 - val_loss: 0.1174 - val_acc: 0.9513\n",
      "Model_GRU_CONV_1-conv-64-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,749,673\n",
      "Trainable params: 169,473\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1062s 856us/step - loss: 0.1178 - acc: 0.9533 - val_loss: 0.1088 - val_acc: 0.9575\n",
      "Model_GRU_CONV_2-conv-64-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 20, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,762,025\n",
      "Trainable params: 181,825\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 739s 596us/step - loss: 0.1187 - acc: 0.9530 - val_loss: 0.1125 - val_acc: 0.9546\n",
      "Model_GRU_CONV_1-conv-128-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 128)           99072     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,831,913\n",
      "Trainable params: 251,713\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1075s 866us/step - loss: 0.1166 - acc: 0.9541 - val_loss: 0.1090 - val_acc: 0.9570\n",
      "Model_GRU_CONV_2-conv-128-layer-0-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 20, 128)           99072     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,881,193\n",
      "Trainable params: 300,993\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 804s 648us/step - loss: 0.1187 - acc: 0.9531 - val_loss: 0.1118 - val_acc: 0.9551\n"
     ]
    }
   ],
   "source": [
    "# GRU model\n",
    "\n",
    "dense_layers = [0]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "# Clearing tensorflow session right before creating the model\n",
    "K.clear_session()\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "      print(NAME)\n",
    "\n",
    "      model = Sequential()\n",
    "\n",
    "      model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "          input_length=MAX_REVIEW_LENGTH_FOR_KERAS_RNN, trainable=False) )\n",
    "\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "      model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      for l in range(conv - 1):\n",
    "        model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "        model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      model.add( CuDNNGRU(128, return_sequences=True))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add( CuDNNGRU(64, return_sequences=False))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Flatten())\n",
    "\n",
    "      for n in range(dense):\n",
    "        model.add(Dense(filters, activation = \"relu\"))\n",
    "\n",
    "      model.add(Dense(1, activation = \"sigmoid\"))\n",
    "      \n",
    "      model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "      model.summary()\n",
    "      model.fit(X_train, y_train, batch_size = 32, epochs = 1, validation_data = [X_val, y_val] )\n",
    "\n",
    "      model.save(\"{}.h5\".format(NAME))\n",
    "      \n",
    "      K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "h4MDkLxoloIq",
    "outputId": "bb5f8e7e-1681-4e14-f437-8223bebbcdf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1P9JpGfcjxCY1z0hsjrb8wxSO7beRG3Ld\n",
      "Uploaded file with ID 1cbDq8msRNhFNlBOFsllt4HW78XODXh8s\n",
      "Uploaded file with ID 1OUOdvCcScI7YHBUJUxRJ5Nvk03MmRlK2\n",
      "Uploaded file with ID 1lWCu1WgA7FZJcATdpjVQdAWk8ddd-55H\n",
      "Uploaded file with ID 1DxVrrj0z-kZ6_NIk4Qb_nLBdUlG8B-Rc\n",
      "Uploaded file with ID 15nmVp9LvSdMLt2GHA7sITjenVTPp0KB7\n"
     ]
    }
   ],
   "source": [
    "# Save models in google drive.\n",
    "\n",
    "dense_layers = [0]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      # 2. Create & upload a file text file.\n",
    "      uploaded = drive.CreateFile()\n",
    "      uploaded.SetContentFile('{}.h5'.format(NAME))\n",
    "      uploaded.Upload()\n",
    "      print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "KCAPLo328kVD",
    "outputId": "a9259118-ad42-45cf-c5b8-a67473b1a6f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_GRU_CONV_1-conv-32-layer-0-dense-> 0.6404140414041405 -> 0.26\n",
      "Model_GRU_CONV_2-conv-32-layer-0-dense-> 0.6370829033367734 -> 0.2\n",
      "Model_GRU_CONV_1-conv-64-layer-0-dense-> 0.6484916201117319 -> 0.27999999999999997\n",
      "Model_GRU_CONV_2-conv-64-layer-0-dense-> 0.6413017468293851 -> 0.26\n",
      "Model_GRU_CONV_1-conv-128-layer-0-dense-> 0.6503504538664828 -> 0.33999999999999997\n",
      "Model_GRU_CONV_2-conv-128-layer-0-dense-> 0.6406303528605687 -> 0.27999999999999997\n"
     ]
    }
   ],
   "source": [
    "#Calculate f1 score of validation data of each models.\n",
    "\n",
    "dense_layers = [0]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      uploadmodel = load_model('{}.h5'.format(NAME))\n",
    "      y_val_prediction = uploadmodel.predict(X_val)\n",
    "            \n",
    "      f1_score, best_threshold_value = F1_Score(y_val, y_val_prediction)\n",
    "      print('{}-> {} -> {}'.format(NAME, f1_score, best_threshold_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daEo6enB91Pk"
   },
   "source": [
    "Comparing these values from LSTM model, with 0 dense layer, which was around 0.5119, these values are comimg out to be the best.\n",
    "Also, LSTM with 1 and 2 dense layer, are very near to these value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3607
    },
    "colab_type": "code",
    "id": "pStaDln-8_tv",
    "outputId": "daff42e8-c73a-4839-9c8a-d0b3a724ee93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_GRU_CONV_1-conv-32-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 128)           62208     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 54,710,601\n",
      "Trainable params: 130,401\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1039s 838us/step - loss: 0.1182 - acc: 0.9535 - val_loss: 0.1132 - val_acc: 0.9551\n",
      "Model_GRU_CONV_2-conv-32-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 20, 128)           62208     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 54,713,705\n",
      "Trainable params: 133,505\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 737s 594us/step - loss: 0.1205 - acc: 0.9524 - val_loss: 0.1117 - val_acc: 0.9558\n",
      "Model_GRU_CONV_1-conv-64-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,753,833\n",
      "Trainable params: 173,633\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1057s 852us/step - loss: 0.1172 - acc: 0.9539 - val_loss: 0.1108 - val_acc: 0.9562\n",
      "Model_GRU_CONV_2-conv-64-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 20, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,766,185\n",
      "Trainable params: 185,985\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 762s 614us/step - loss: 0.1208 - acc: 0.9524 - val_loss: 0.1139 - val_acc: 0.9555\n",
      "Model_GRU_CONV_1-conv-128-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 128)           99072     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 54,840,297\n",
      "Trainable params: 260,097\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1097s 884us/step - loss: 0.1169 - acc: 0.9541 - val_loss: 0.1103 - val_acc: 0.9575\n",
      "Model_GRU_CONV_2-conv-128-layer-1-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 128)           115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 20, 128)           99072     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 54,889,577\n",
      "Trainable params: 309,377\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 836s 674us/step - loss: 0.1192 - acc: 0.9527 - val_loss: 0.1103 - val_acc: 0.9565\n"
     ]
    }
   ],
   "source": [
    "# GRU model\n",
    "\n",
    "dense_layers = [1]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "# Clearing tensorflow session right before creating the model\n",
    "K.clear_session()\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "      print(NAME)\n",
    "\n",
    "      model = Sequential()\n",
    "\n",
    "      model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "          input_length=MAX_REVIEW_LENGTH_FOR_KERAS_RNN, trainable=False) )\n",
    "\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "      model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      for l in range(conv - 1):\n",
    "        model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "        model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      model.add( CuDNNGRU(128, return_sequences=True))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add( CuDNNGRU(64, return_sequences=False))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Flatten())\n",
    "\n",
    "      for n in range(dense):\n",
    "        model.add(Dense(filters, activation = \"relu\"))\n",
    "\n",
    "      model.add(Dense(1, activation = \"sigmoid\"))\n",
    "      \n",
    "      model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "      model.summary()\n",
    "      model.fit(X_train, y_train, batch_size = 32, epochs = 1, validation_data = [X_val, y_val] )\n",
    "\n",
    "      model.save(\"{}.h5\".format(NAME))\n",
    "      \n",
    "      K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "LPkLaLfO-mBJ",
    "outputId": "0cb6f46d-f797-4174-f37b-2932a9a41f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1b5R65sGA4yfUjYxWTD_JLYwpZ_pTELbv\n",
      "Uploaded file with ID 1bx0e35iDkTFVRyvo_PTa-QrU35llm10a\n",
      "Uploaded file with ID 1GDDS6p_MTrnx8mDDmv1mmwyCC53Dfwdd\n",
      "Uploaded file with ID 1shAjvH98fuGl6mQH-gXUynZitvEEbzlC\n",
      "Uploaded file with ID 14OHtSF9WJFmNdKbZp0Db3ivreh50UEDY\n",
      "Uploaded file with ID 1QQ_-_r8w3zH-VzgxfMPxep_JERYTFXQM\n"
     ]
    }
   ],
   "source": [
    "# Save models in google drive.\n",
    "dense_layers = [1]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      # 2. Create & upload a file text file.\n",
    "      uploaded = drive.CreateFile()\n",
    "      uploaded.SetContentFile('{}.h5'.format(NAME))\n",
    "      uploaded.Upload()\n",
    "      print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "kzCFjeBJUM4K",
    "outputId": "6ed081a6-9753-44c2-8adc-34a62246154c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_GRU_CONV_1-conv-32-layer-1-dense-> 0.6392196892367019 -> 0.3799999999999999\n",
      "Model_GRU_CONV_2-conv-32-layer-1-dense-> 0.63967702141976 -> 0.27999999999999997\n",
      "Model_GRU_CONV_1-conv-64-layer-1-dense-> 0.6459059757123964 -> 0.41999999999999993\n",
      "Model_GRU_CONV_2-conv-64-layer-1-dense-> 0.6368477103301384 -> 0.31999999999999995\n",
      "Model_GRU_CONV_1-conv-128-layer-1-dense-> 0.6519886363636364 -> 0.29999999999999993\n",
      "Model_GRU_CONV_2-conv-128-layer-1-dense-> 0.6435587670768884 -> 0.29999999999999993\n"
     ]
    }
   ],
   "source": [
    "#Calculate f1 score of validation data of each models.\n",
    "\n",
    "dense_layers = [1]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      uploadmodel = load_model('{}.h5'.format(NAME))\n",
    "      y_val_prediction = uploadmodel.predict(X_val)\n",
    "            \n",
    "      f1_score, best_threshold_value = F1_Score(y_val, y_val_prediction)\n",
    "      print('{}-> {} -> {}'.format(NAME, f1_score, best_threshold_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LlnA9ubVu1z"
   },
   "source": [
    "There is a slight increament in this GRU model with 1 dense layer, from 0 dense layer, from 0.6503 to 0.6519.\n",
    "After this, we will try model with 2 dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yaSwaScVECf"
   },
   "outputs": [],
   "source": [
    "# after that, we wil make a decision on different word embeddings, selection of top 6 models, applyong it on different word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2553
    },
    "colab_type": "code",
    "id": "3vSsweBmWfXb",
    "outputId": "6d91cb5f-aa0f-457f-ce46-7d45a1adba5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_GRU_CONV_1-conv-32-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 128)           62208     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 54,711,657\n",
      "Trainable params: 131,457\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1035s 835us/step - loss: 0.1414 - acc: 0.9482 - val_loss: 0.1313 - val_acc: 0.9506\n",
      "Model_GRU_CONV_2-conv-32-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 20, 128)           62208     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 54,714,761\n",
      "Trainable params: 134,561\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 733s 591us/step - loss: 0.1427 - acc: 0.9480 - val_loss: 0.1357 - val_acc: 0.9489\n",
      "Model_GRU_CONV_1-conv-64-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 40, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,757,993\n",
      "Trainable params: 177,793\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 1046s 843us/step - loss: 0.1398 - acc: 0.9488 - val_loss: 0.1266 - val_acc: 0.9520\n",
      "Model_GRU_CONV_2-conv-64-layer-2-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 300)           54580200  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (None, 20, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 54,770,345\n",
      "Trainable params: 190,145\n",
      "Non-trainable params: 54,580,200\n",
      "_________________________________________________________________\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      " 617376/1240815 [=============>................] - ETA: 6:16 - loss: 0.1460 - acc: 0.9471Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "# GRU model\n",
    "\n",
    "dense_layers = [2]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "# Clearing tensorflow session right before creating the model\n",
    "K.clear_session()\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "      print(NAME)\n",
    "\n",
    "      model = Sequential()\n",
    "\n",
    "      model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "          input_length=MAX_REVIEW_LENGTH_FOR_KERAS_RNN, trainable=False) )\n",
    "\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "      model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      for l in range(conv - 1):\n",
    "        model.add(Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "        model.add(MaxPool1D(pool_size = 2))\n",
    "\n",
    "      model.add( CuDNNGRU(128, return_sequences=True))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add( CuDNNGRU(64, return_sequences=False))\n",
    "      model.add(Dropout(0.2))\n",
    "\n",
    "      model.add(Flatten())\n",
    "\n",
    "      for n in range(dense):\n",
    "        model.add(Dense(filters, activation = \"relu\"))\n",
    "\n",
    "      model.add(Dense(1, activation = \"sigmoid\"))\n",
    "      \n",
    "      model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "      model.summary()\n",
    "      model.fit(X_train, y_train, batch_size = 32, epochs = 1, validation_data = [X_val, y_val] )\n",
    "\n",
    "      model.save(\"{}.h5\".format(NAME))\n",
    "      \n",
    "      K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "uXkpRrDuog6K",
    "outputId": "29bb6d66-f253-415e-9015-e8d0adcbe8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1J0y27w63LJNekDUJ95PQl5Uf3NInl6IE\n",
      "Uploaded file with ID 1FPHKwD1NwziFIIQirAroqoqnadQbRZJl\n",
      "Uploaded file with ID 1XO2gp7wDHsu8rLwARJmZZfBtDf6dacHu\n",
      "Uploaded file with ID 1vU1eAeZi8DuWjwxhdw_sxMieEcj5P4Sy\n",
      "Uploaded file with ID 1ncfXOJAxeNEC8jaafcXX2nLDsJ5H6Tb6\n",
      "Uploaded file with ID 1nhtgkg-dB9OUZuLcy5gDg79jtzY-AolX\n"
     ]
    }
   ],
   "source": [
    "# Save models in google drive.\n",
    "dense_layers = [2]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      # 2. Create & upload a file text file.\n",
    "      uploaded = drive.CreateFile()\n",
    "      uploaded.SetContentFile('{}.h5'.format(NAME))\n",
    "      uploaded.Upload()\n",
    "      print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "RGHCELZJotID",
    "outputId": "de4c05a5-917c-476d-8b5a-bea7d66378e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_GRU_CONV_1-conv-32-layer-2-dense-> 0.5761239582110578 -> 0.26\n",
      "Model_GRU_CONV_2-conv-32-layer-2-dense-> 0.5683994528043775 -> 0.29999999999999993\n",
      "Model_GRU_CONV_1-conv-64-layer-2-dense-> 0.5886801099908342 -> 0.27999999999999997\n",
      "Model_GRU_CONV_2-conv-64-layer-2-dense-> 0.5808533524560773 -> 0.31999999999999995\n",
      "Model_GRU_CONV_1-conv-128-layer-2-dense-> 0.5874602987883778 -> 0.4399999999999999\n",
      "Model_GRU_CONV_2-conv-128-layer-2-dense-> 0.5788686768003986 -> 0.2\n"
     ]
    }
   ],
   "source": [
    "#Calculate f1 score of validation data of each models.\n",
    "\n",
    "dense_layers = [2]\n",
    "filter_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2]\n",
    "\n",
    "for dense in dense_layers:\n",
    "  for filters in filter_sizes:\n",
    "    for conv in conv_layers:\n",
    "\n",
    "      NAME = \"Model_GRU_CONV_{}-conv-{}-layer-{}-dense\".format(conv, filters, dense)\n",
    "\n",
    "      uploadmodel = load_model('{}.h5'.format(NAME))\n",
    "      y_val_prediction = uploadmodel.predict(X_val)\n",
    "            \n",
    "      f1_score, best_threshold_value = F1_Score(y_val, y_val_prediction)\n",
    "      print('{}-> {} -> {}'.format(NAME, f1_score, best_threshold_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FfnVJboAHNC"
   },
   "outputs": [],
   "source": [
    "# Model_LSTM_CONV_1-conv-64-layer-1-dense-> 0.6570338689168882 -> 0.24\n",
    "# Model_GRU_CONV_1-conv-128-layer-1-dense-> 0.6519886363636364 -> 0.29999999999999993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzO34R3M77xn"
   },
   "outputs": [],
   "source": [
    "# upload models from google drive.\n",
    "\n",
    "NAME = 'Model_LSTM_CONV_1-conv-64-layer-1-dense'\n",
    "NAME2 = 'Model_GRU_CONV_1-conv-128-layer-1-dense'\n",
    "\n",
    "downloaded = drive.CreateFile({'id': '1Q7oTH13l-yn7TIrhb4rJW8L2KdN-mmzm'})\n",
    "downloaded.GetContentFile(\"{}.h5\".format(NAME))\n",
    "\n",
    "downloaded = drive.CreateFile({'id': '14OHtSF9WJFmNdKbZp0Db3ivreh50UEDY'})\n",
    "downloaded.GetContentFile(\"{}.h5\".format(NAME2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5et7JtER86sq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Quora Insincere Questions.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
